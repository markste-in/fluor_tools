{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84526c6",
   "metadata": {},
   "source": [
    "# üìä Create Training Data from Experimental CSV\n",
    "\n",
    "This notebook transforms your experimental data (Daten_clean.csv) into the format required for Fluor-RLAT training.\n",
    "\n",
    "**Input:** CSV with columns: `name, solvent, abs, em, epsilon, mw, plqy, smiles`\n",
    "\n",
    "**Output:** Training data files for each property:\n",
    "- `new_train_{target}.csv` - Main data (152 columns)\n",
    "- `new_train_smiles_{target}.csv` - Molecule Morgan fingerprints (1024 columns)\n",
    "- `new_train_sol_{target}.csv` - Solvent Morgan fingerprints (1024 columns)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "371bb7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m36.7/36.7 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h‚úÖ Dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Install Dependencies\n",
    "# ============================================================================\n",
    "!pip install rdkit -q\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b512e128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Import Libraries\n",
    "# ============================================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d519699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Mount Google Drive\n",
    "# ============================================================================\n",
    "from google.colab import drive\n",
    "\n",
    "# Check if already mounted\n",
    "import os\n",
    "if os.path.exists('/content/drive/MyDrive'):\n",
    "    print(\"‚úÖ Google Drive already mounted\")\n",
    "else:\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a4fb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Cloning repository...\n",
      "‚úÖ Repository cloned!\n",
      "üìÅ Reference data: ./fluor_tools/Fluor-RLAT/data\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Clone Repository (for reference data)\n",
    "# ============================================================================\n",
    "REPO_URL = \"https://github.com/markste-in/fluor_tools.git\"\n",
    "REPO_DIR = \"fluor_tools\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(f\"üì• Cloning repository...\")\n",
    "    !git clone {REPO_URL} -q\n",
    "    print(\"‚úÖ Repository cloned!\")\n",
    "else:\n",
    "    print(f\"‚úÖ Repository already exists\")\n",
    "\n",
    "DATA_DIR = f'./{REPO_DIR}/Fluor-RLAT/data'\n",
    "print(f\"üìÅ Reference data: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ba0b4",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2770727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Input:  /content/drive/MyDrive/fluor_models/Daten_clean.csv\n",
      "üìÇ Output: /content/drive/MyDrive/fluor_models/training_data\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# Input: Your experimental data CSV\n",
    "INPUT_CSV = '/content/drive/MyDrive/fluor_models/Daten_clean.csv'\n",
    "\n",
    "# Output: Where to save the training data\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/fluor_models/training_data'\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Solvent SMILES mapping (German names to SMILES)\n",
    "SOLVENT_NAME_TO_SMILES = {\n",
    "    'Toluol': 'Cc1ccccc1',\n",
    "    'toluol': 'Cc1ccccc1',\n",
    "    'Toluene': 'Cc1ccccc1',\n",
    "    'toluene': 'Cc1ccccc1',\n",
    "    'EtOH': 'CCO',\n",
    "    'Ethanol': 'CCO',\n",
    "    'MeOH': 'CO',\n",
    "    'Methanol': 'CO',\n",
    "    'DCM': 'ClCCl',\n",
    "    'CH2Cl2': 'ClCCl',\n",
    "    'Dichlormethan': 'ClCCl',\n",
    "    'CHCl3': 'ClC(Cl)Cl',\n",
    "    'Chloroform': 'ClC(Cl)Cl',\n",
    "    'Benzol': 'c1ccccc1',\n",
    "    'Benzene': 'c1ccccc1',\n",
    "    'DMSO': 'CS(C)=O',\n",
    "    'Wasser': 'O',\n",
    "    'Water': 'O',\n",
    "    'Aceton': 'CC(C)=O',\n",
    "    'Acetone': 'CC(C)=O',\n",
    "    'THF': 'C1CCOC1',\n",
    "    'Cyclohexan': 'C1CCCCC1',\n",
    "    'Cyclohexane': 'C1CCCCC1',\n",
    "    'Hexan': 'CCCCCC',\n",
    "    'Hexane': 'CCCCCC',\n",
    "    'Acetonitril': 'CC#N',\n",
    "    'Acetonitrile': 'CC#N',\n",
    "    'ACN': 'CC#N',\n",
    "    'DMF': 'CN(C)C=O',\n",
    "    'Diethylether': 'CCOCC',\n",
    "    'Et2O': 'CCOCC',\n",
    "}\n",
    "\n",
    "print(f\"üìÇ Input:  {INPUT_CSV}\")\n",
    "print(f\"üìÇ Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbeb87c",
   "metadata": {},
   "source": [
    "## 3. Load Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe53555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 73 solvent mappings\n",
      "‚úÖ Loaded 136 substructure patterns\n",
      "\n",
      "Solvent SMILES ‚Üí Number mapping (first 10):\n",
      "  ClCCl: 0\n",
      "  CO: 1\n",
      "  CCO: 2\n",
      "  ClC(Cl)Cl: 3\n",
      "  CC#N: 4\n",
      "  C1CCOC1: 5\n",
      "  Cc1ccccc1: 6\n",
      "  CS(C)=O: 7\n",
      "  O: 8\n",
      "  CN(C)C=O: 9\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Load Reference Data (solvent mapping and substructures)\n",
    "# ============================================================================\n",
    "\n",
    "# Load solvent mapping from original training data\n",
    "solvent_mapping_df = pd.read_csv(f'{DATA_DIR}/00_solvent_mapping.csv')\n",
    "SOLVENT_SMILES_TO_NUM = dict(zip(solvent_mapping_df['solvent'], solvent_mapping_df['solvent_num']))\n",
    "print(f\"‚úÖ Loaded {len(SOLVENT_SMILES_TO_NUM)} solvent mappings\")\n",
    "\n",
    "# Load substructure patterns for scaffold detection\n",
    "substructure_df = pd.read_csv(f'{DATA_DIR}/00_mmp_substructure.csv')\n",
    "SUBSTRUCTURE_PATTERNS = []\n",
    "for idx, row in substructure_df.iterrows():\n",
    "    try:\n",
    "        # Replace attachment point with wildcard for substructure matching\n",
    "        smarts = row['fragment'].replace('[*:1]', '*')\n",
    "        pattern = Chem.MolFromSmarts(smarts)\n",
    "        if pattern:\n",
    "            SUBSTRUCTURE_PATTERNS.append((idx, pattern))\n",
    "    except:\n",
    "        pass\n",
    "print(f\"‚úÖ Loaded {len(SUBSTRUCTURE_PATTERNS)} substructure patterns\")\n",
    "\n",
    "# Tag name mapping (based on scaffold detection)\n",
    "TAG_MAPPING = {\n",
    "    'BODIPY': 5,\n",
    "    'Coumarin': 3,\n",
    "    'Rhodamine': 4,\n",
    "    'Cyanine': 6,\n",
    "    'PAHs': 8,\n",
    "    'Other': 0\n",
    "}\n",
    "\n",
    "print(\"\\nSolvent SMILES ‚Üí Number mapping (first 10):\")\n",
    "for smiles, num in list(SOLVENT_SMILES_TO_NUM.items())[:10]:\n",
    "    print(f\"  {smiles}: {num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990cec53",
   "metadata": {},
   "source": [
    "## 4. Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240727a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loaded 126 rows from /content/drive/MyDrive/fluor_models/Daten_clean.csv\n",
      "\n",
      "Columns: ['name', 'solvent', 'abs', 'em', 'epsilon', 'mw', 'plqy', 'smiles']\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-765b67b8-8122-402a-afa9-b74e6792df10\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>solvent</th>\n",
       "      <th>abs</th>\n",
       "      <th>em</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>mw</th>\n",
       "      <th>plqy</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBOT</td>\n",
       "      <td>Toluol</td>\n",
       "      <td>376.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>47577.985</td>\n",
       "      <td>430.570</td>\n",
       "      <td>1.00</td>\n",
       "      <td>CC(C)(C)c1ccc2oc(nc2c1)c1sc(cc1)c1oc2ccc(cc2n1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coumarin 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC1=CC(=O)Oc2cc(ccc21)N(CC)CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coumarin 343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>285.299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O=C1Oc2c3CCCN4CCCc(cc2C=C1C(=O)O)c43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coumarin 30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347.481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cn1c(nc2ccccc12)C1=Cc2ccc(cc2OC1=O)N(CC)CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coumarin 102</td>\n",
       "      <td>Toluol</td>\n",
       "      <td>373.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.317</td>\n",
       "      <td>0.77</td>\n",
       "      <td>O=C1C=C(C)c2cc3CCCN4CCCc(c2O1)c43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-765b67b8-8122-402a-afa9-b74e6792df10')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-765b67b8-8122-402a-afa9-b74e6792df10 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-765b67b8-8122-402a-afa9-b74e6792df10');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              name solvent    abs     em    epsilon       mw  plqy  \\\n",
       "0             BBOT  Toluol  376.0  434.0  47577.985  430.570  1.00   \n",
       "1       Coumarin 1     NaN    NaN    NaN        NaN  231.295   NaN   \n",
       "2  Coumarin 343¬†¬†¬†     NaN    NaN    NaN        NaN  285.299   NaN   \n",
       "3      Coumarin 30     NaN    NaN    NaN        NaN  347.481   NaN   \n",
       "4     Coumarin 102  Toluol  373.0  420.0        NaN  255.317  0.77   \n",
       "\n",
       "                                              smiles  \n",
       "0  CC(C)(C)c1ccc2oc(nc2c1)c1sc(cc1)c1oc2ccc(cc2n1...  \n",
       "1                      CC1=CC(=O)Oc2cc(ccc21)N(CC)CC  \n",
       "2               O=C1Oc2c3CCCN4CCCc(cc2C=C1C(=O)O)c43  \n",
       "3         Cn1c(nc2ccccc12)C1=Cc2ccc(cc2OC1=O)N(CC)CC  \n",
       "4                  O=C1C=C(C)c2cc3CCCN4CCCc(c2O1)c43  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Data availability per property:\n",
      "  abs: 119 samples with data\n",
      "  em: 117 samples with data\n",
      "  plqy: 10 samples with data\n",
      "  epsilon: 78 samples with data\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Load Input CSV\n",
    "# ============================================================================\n",
    "\n",
    "input_df = pd.read_csv(INPUT_CSV)\n",
    "print(f\"üìÇ Loaded {len(input_df)} rows from {INPUT_CSV}\")\n",
    "print(f\"\\nColumns: {list(input_df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "display(input_df.head())\n",
    "\n",
    "# Check data availability per property\n",
    "print(\"\\nüìä Data availability per property:\")\n",
    "for prop in ['abs', 'em', 'plqy', 'epsilon']:\n",
    "    if prop in input_df.columns:\n",
    "        count = input_df[prop].notna().sum()\n",
    "        print(f\"  {prop}: {count} samples with data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c506f2",
   "metadata": {},
   "source": [
    "## 5. Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fe0b550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature extraction functions defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Feature Extraction Functions\n",
    "# ============================================================================\n",
    "\n",
    "def compute_morgan_fingerprint(smiles, radius=2, n_bits=1024):\n",
    "    \"\"\"Generate Morgan fingerprint as numpy array.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=n_bits)\n",
    "    return np.array(fp, dtype=np.int32)\n",
    "\n",
    "\n",
    "def compute_molecular_descriptors(smiles):\n",
    "    \"\"\"Compute molecular descriptors matching training data format.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    # Count double bonds (including aromatic)\n",
    "    double_bond_count = sum(\n",
    "        1 for bond in mol.GetBonds() \n",
    "        if bond.GetBondType() == Chem.BondType.DOUBLE or bond.GetIsAromatic()\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'Molecular_Weight': Descriptors.MolWt(mol),\n",
    "        'LogP': Descriptors.MolLogP(mol),\n",
    "        'TPSA': Descriptors.TPSA(mol),\n",
    "        'Double_Bond_Count': double_bond_count,\n",
    "        'Ring_Count': mol.GetRingInfo().NumRings(),\n",
    "    }\n",
    "\n",
    "\n",
    "def detect_scaffold_tag(smiles):\n",
    "    \"\"\"Detect scaffold type and return tag number and name.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return 0, 'Other'\n",
    "    \n",
    "    # BODIPY pattern: [B](-F)(-F) connected to two nitrogens\n",
    "    bodipy_pattern = Chem.MolFromSmarts('[#5](-F)(-F)~[#7]')\n",
    "    if bodipy_pattern and mol.HasSubstructMatch(bodipy_pattern):\n",
    "        return 5, 'BODIPY'\n",
    "    \n",
    "    # Coumarin pattern: benzene fused with pyrone\n",
    "    coumarin_pattern = Chem.MolFromSmarts('O=C1C=Cc2ccccc2O1')\n",
    "    if coumarin_pattern and mol.HasSubstructMatch(coumarin_pattern):\n",
    "        return 3, 'Coumarin'\n",
    "    \n",
    "    # Rhodamine pattern: xanthene core\n",
    "    rhodamine_pattern = Chem.MolFromSmarts('c1ccc2c(c1)C(c1ccccc1O2)c1ccccc1')\n",
    "    if rhodamine_pattern and mol.HasSubstructMatch(rhodamine_pattern):\n",
    "        return 4, 'Rhodamine'\n",
    "    \n",
    "    # Cyanine pattern: polymethine chain\n",
    "    cyanine_pattern = Chem.MolFromSmarts('[N+]=C-C=C-C=C-[N]')\n",
    "    if cyanine_pattern and mol.HasSubstructMatch(cyanine_pattern):\n",
    "        return 6, 'Cyanine'\n",
    "    \n",
    "    # PAHs: multiple fused aromatic rings\n",
    "    if mol.GetRingInfo().NumRings() >= 3:\n",
    "        aromatic_rings = sum(1 for ring in mol.GetRingInfo().AtomRings() \n",
    "                            if all(mol.GetAtomWithIdx(i).GetIsAromatic() for i in ring))\n",
    "        if aromatic_rings >= 3:\n",
    "            return 8, 'PAHs'\n",
    "    \n",
    "    return 0, 'Other'\n",
    "\n",
    "\n",
    "def compute_scaffold_flags(smiles, patterns):\n",
    "    \"\"\"Compute binary scaffold flags for 136 substructure patterns.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    flags = np.zeros(136, dtype=np.int32)\n",
    "    \n",
    "    if mol is None:\n",
    "        return flags\n",
    "    \n",
    "    for idx, pattern in patterns:\n",
    "        if idx < 136:\n",
    "            try:\n",
    "                if mol.HasSubstructMatch(pattern):\n",
    "                    flags[idx] = 1\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return flags\n",
    "\n",
    "\n",
    "def get_solvent_num(solvent_name, solvent_smiles_to_num, name_to_smiles):\n",
    "    \"\"\"Convert solvent name to solvent number.\"\"\"\n",
    "    # First try to get SMILES from name\n",
    "    solvent_smiles = name_to_smiles.get(solvent_name)\n",
    "    if solvent_smiles:\n",
    "        # Then get number from SMILES\n",
    "        return solvent_smiles_to_num.get(solvent_smiles, 0), solvent_smiles\n",
    "    return 0, None\n",
    "\n",
    "\n",
    "print(\"‚úÖ Feature extraction functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdf9397",
   "metadata": {},
   "source": [
    "## 6. Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24e90f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Processing molecules...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ebd849c0d545c28432d2042a11248e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] Explicit valence for atom # 10 B, 4, is greater than permitted\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:50] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Processed 114 molecules\n",
      "‚ö†Ô∏è  Skipped 12 molecules\n",
      "\n",
      "Skipped molecules:\n",
      "  ‚Ä¢ Coumarin 1: Unknown solvent: nan\n",
      "  ‚Ä¢ Coumarin 343¬†¬†¬†: Unknown solvent: nan\n",
      "  ‚Ä¢ Coumarin 30: Unknown solvent: nan\n",
      "  ‚Ä¢ Coumarin 153: Unknown solvent: nan\n",
      "  ‚Ä¢ FR-NH2: Unknown solvent: 10mM Tris pH8\n",
      "  ‚Ä¢ Nilblau: Unknown solvent: nan\n",
      "  ‚Ä¢ Rh-123: Unknown solvent: nan\n",
      "  ‚Ä¢ Rh-110: Unknown solvent: nan\n",
      "  ‚Ä¢ Rh-B: Unknown solvent: 10mM Tris pH8\n",
      "  ‚Ä¢ Rh-NH2: Unknown solvent: 10mM Tris pH8\n",
      "  ... and 2 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:59:51] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Process All Molecules\n",
    "# ============================================================================\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "processed_rows = []\n",
    "smiles_fps = []\n",
    "solvent_fps = []\n",
    "skipped = []\n",
    "\n",
    "print(\"üîÑ Processing molecules...\\n\")\n",
    "\n",
    "for idx, row in tqdm(input_df.iterrows(), total=len(input_df), desc=\"Processing\"):\n",
    "    smiles = row.get('smiles')\n",
    "    solvent_name = str(row.get('solvent', '')).strip()\n",
    "    \n",
    "    # Skip if no SMILES\n",
    "    if pd.isna(smiles) or not smiles:\n",
    "        skipped.append((row.get('name', idx), 'No SMILES'))\n",
    "        continue\n",
    "    \n",
    "    # Get solvent info\n",
    "    solvent_num, solvent_smiles = get_solvent_num(\n",
    "        solvent_name, SOLVENT_SMILES_TO_NUM, SOLVENT_NAME_TO_SMILES\n",
    "    )\n",
    "    \n",
    "    if solvent_smiles is None:\n",
    "        skipped.append((row.get('name', idx), f'Unknown solvent: {solvent_name}'))\n",
    "        continue\n",
    "    \n",
    "    # Compute Morgan fingerprints\n",
    "    mol_fp = compute_morgan_fingerprint(smiles)\n",
    "    sol_fp = compute_morgan_fingerprint(solvent_smiles)\n",
    "    \n",
    "    if mol_fp is None:\n",
    "        skipped.append((row.get('name', idx), 'Invalid molecule SMILES'))\n",
    "        continue\n",
    "    if sol_fp is None:\n",
    "        skipped.append((row.get('name', idx), 'Invalid solvent SMILES'))\n",
    "        continue\n",
    "    \n",
    "    # Compute molecular descriptors\n",
    "    descriptors = compute_molecular_descriptors(smiles)\n",
    "    if descriptors is None:\n",
    "        skipped.append((row.get('name', idx), 'Could not compute descriptors'))\n",
    "        continue\n",
    "    \n",
    "    # Detect scaffold tag\n",
    "    tag, tag_name = detect_scaffold_tag(smiles)\n",
    "    \n",
    "    # Compute scaffold flags\n",
    "    scaffold_flags = compute_scaffold_flags(smiles, SUBSTRUCTURE_PATTERNS)\n",
    "    \n",
    "    # Compute log(epsilon) -> k\n",
    "    epsilon = row.get('epsilon', np.nan)\n",
    "    k = np.log10(epsilon) if pd.notna(epsilon) and epsilon > 0 else np.nan\n",
    "    \n",
    "    # Build the row matching train_*.csv format\n",
    "    processed_row = {\n",
    "        'split': 'train',  # Will be added to training set\n",
    "        'smiles': smiles,\n",
    "        'solvent': solvent_smiles,\n",
    "        'abs': row.get('abs', np.nan),\n",
    "        'em': row.get('em', np.nan),\n",
    "        'plqy': row.get('plqy', np.nan),\n",
    "        'k': k,\n",
    "        'tag_name': tag_name,\n",
    "        'solvent_num': solvent_num,\n",
    "        'tag': tag,\n",
    "        'Molecular_Weight': descriptors['Molecular_Weight'],\n",
    "        'LogP': descriptors['LogP'],\n",
    "        'TPSA': descriptors['TPSA'],\n",
    "        'Double_Bond_Count': descriptors['Double_Bond_Count'],\n",
    "        'Ring_Count': descriptors['Ring_Count'],\n",
    "        'unimol_plus': 3.0,  # Default value\n",
    "    }\n",
    "    \n",
    "    # Add scaffold flags\n",
    "    for i in range(136):\n",
    "        processed_row[f'fragment_{i+1}'] = scaffold_flags[i]\n",
    "    \n",
    "    processed_rows.append(processed_row)\n",
    "    smiles_fps.append(mol_fp)\n",
    "    solvent_fps.append(sol_fp)\n",
    "\n",
    "print(f\"\\n‚úÖ Processed {len(processed_rows)} molecules\")\n",
    "print(f\"‚ö†Ô∏è  Skipped {len(skipped)} molecules\")\n",
    "\n",
    "if skipped:\n",
    "    print(\"\\nSkipped molecules:\")\n",
    "    for name, reason in skipped[:10]:\n",
    "        print(f\"  ‚Ä¢ {name}: {reason}\")\n",
    "    if len(skipped) > 10:\n",
    "        print(f\"  ... and {len(skipped) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0c0a9",
   "metadata": {},
   "source": [
    "## 7. Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13bad592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Main DataFrame: (114, 152)\n",
      "‚úÖ SMILES FP DataFrame: (114, 1024)\n",
      "‚úÖ Solvent FP DataFrame: (114, 1024)\n",
      "\n",
      "üìä Data summary:\n",
      "                                              smiles    solvent    abs     em  \\\n",
      "0  CC(C)(C)c1ccc2oc(nc2c1)c1sc(cc1)c1oc2ccc(cc2n1...  Cc1ccccc1  376.0  434.0   \n",
      "1                  O=C1C=C(C)c2cc3CCCN4CCCc(c2O1)c43  Cc1ccccc1  373.0  420.0   \n",
      "2            O=C1Oc2cc(ccc2C=C1c1sc2ccccc2n1)N(CC)CC  Cc1ccccc1  439.0  487.0   \n",
      "3  O=C(N1CCC(CC1)CN)c1ccccc1C1=C2C=C\\C(=N/CC(F)(F...         CO  512.0  533.0   \n",
      "4        O=C1Oc2cc(ccc2C=C1c1oc2ccc(Cl)cc2n1)N(CC)CC  Cc1ccccc1  434.0  475.0   \n",
      "5       O=C1Oc2cc(ccc2C(C#N)=C1c1oc2ccccc2n1)N(CC)CC  Cc1ccccc1  523.0  566.0   \n",
      "6       O=C1Oc2cc(ccc2C(C#N)=C1c1oc2ccccc2n1)N(CC)CC  ClC(Cl)Cl  534.0  585.0   \n",
      "7            O=C1C=C2Oc3cc(ccc3N=C2c2ccccc12)N(CC)CC  Cc1ccccc1  525.0  585.0   \n",
      "8  CC\\1=CC2=C(c3cc(C)c(NCC)cc3OC2=C/C/1=[NH+]/CC)...         CO  528.0  551.0   \n",
      "9  O=C([O-])c1ccccc1C1=C2C=C3CCC[N+]=4CCCC(=C2Oc2...         CO  567.0  588.0   \n",
      "\n",
      "    plqy         k tag_name  \n",
      "0  1.000  4.677406     PAHs  \n",
      "1  0.770       NaN    Other  \n",
      "2  0.720  4.705174     PAHs  \n",
      "3    NaN  4.750565     PAHs  \n",
      "4  0.720  4.687377     PAHs  \n",
      "5    NaN       NaN     PAHs  \n",
      "6    NaN       NaN     PAHs  \n",
      "7    NaN  4.594951     PAHs  \n",
      "8    NaN  4.947047     PAHs  \n",
      "9  0.913  4.865436     PAHs  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Create DataFrames\n",
    "# ============================================================================\n",
    "\n",
    "# Main data DataFrame\n",
    "main_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Fingerprint DataFrames\n",
    "smiles_fp_df = pd.DataFrame(smiles_fps, columns=[f'smiles_fp_{i}' for i in range(1024)])\n",
    "solvent_fp_df = pd.DataFrame(solvent_fps, columns=[f'sol_fp_{i}' for i in range(1024)])\n",
    "\n",
    "print(f\"‚úÖ Main DataFrame: {main_df.shape}\")\n",
    "print(f\"‚úÖ SMILES FP DataFrame: {smiles_fp_df.shape}\")\n",
    "print(f\"‚úÖ Solvent FP DataFrame: {solvent_fp_df.shape}\")\n",
    "\n",
    "# Show summary\n",
    "print(\"\\nüìä Data summary:\")\n",
    "print(main_df[['smiles', 'solvent', 'abs', 'em', 'plqy', 'k', 'tag_name']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055c4d5f",
   "metadata": {},
   "source": [
    "## 8. Save Training Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "084ff99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving training data files...\n",
      "\n",
      "‚úÖ abs (Absorption wavelength (nm)):\n",
      "   ‚Ä¢ 114 samples\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_abs.csv\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_smiles_abs.csv\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_sol_abs.csv\n",
      "\n",
      "‚úÖ em (Emission wavelength (nm)):\n",
      "   ‚Ä¢ 112 samples\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_em.csv\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_smiles_em.csv\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_sol_em.csv\n",
      "\n",
      "‚úÖ plqy (Quantum yield (0-1)):\n",
      "   ‚Ä¢ 10 samples\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_plqy.csv\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_smiles_plqy.csv\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_sol_plqy.csv\n",
      "\n",
      "‚úÖ k (Log molar absorptivity):\n",
      "   ‚Ä¢ 74 samples\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_k.csv\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_smiles_k.csv\n",
      "   ‚Ä¢ /content/drive/MyDrive/fluor_models/training_data/new_train_sol_k.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Save Training Data for Each Target Property\n",
    "# ============================================================================\n",
    "\n",
    "targets = {\n",
    "    'abs': 'Absorption wavelength (nm)',\n",
    "    'em': 'Emission wavelength (nm)',\n",
    "    'plqy': 'Quantum yield (0-1)',\n",
    "    'k': 'Log molar absorptivity'\n",
    "}\n",
    "\n",
    "print(\"üíæ Saving training data files...\\n\")\n",
    "\n",
    "for target, description in targets.items():\n",
    "    # Filter rows with valid target values\n",
    "    mask = main_df[target].notna()\n",
    "    target_df = main_df[mask].copy()\n",
    "    target_smiles_fp = smiles_fp_df[mask].copy()\n",
    "    target_solvent_fp = solvent_fp_df[mask].copy()\n",
    "    \n",
    "    if len(target_df) == 0:\n",
    "        print(f\"‚ö†Ô∏è  {target}: No valid data, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Reset indices\n",
    "    target_df = target_df.reset_index(drop=True)\n",
    "    target_smiles_fp = target_smiles_fp.reset_index(drop=True)\n",
    "    target_solvent_fp = target_solvent_fp.reset_index(drop=True)\n",
    "    \n",
    "    # Save files\n",
    "    main_path = os.path.join(OUTPUT_DIR, f'new_train_{target}.csv')\n",
    "    smiles_path = os.path.join(OUTPUT_DIR, f'new_train_smiles_{target}.csv')\n",
    "    solvent_path = os.path.join(OUTPUT_DIR, f'new_train_sol_{target}.csv')\n",
    "    \n",
    "    target_df.to_csv(main_path, index=False)\n",
    "    target_smiles_fp.to_csv(smiles_path, index=False)\n",
    "    target_solvent_fp.to_csv(solvent_path, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ {target} ({description}):\")\n",
    "    print(f\"   ‚Ä¢ {len(target_df)} samples\")\n",
    "    print(f\"   ‚Ä¢ {main_path}\")\n",
    "    print(f\"   ‚Ä¢ {smiles_path}\")\n",
    "    print(f\"   ‚Ä¢ {solvent_path}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784af6ea",
   "metadata": {},
   "source": [
    "## 9. Merge with Existing Training Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99675a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÄ Merging new data with existing training data...\n",
      "\n",
      "‚úÖ abs: 21948 existing + 114 new = 22062 total\n",
      "   ‚Üí /content/drive/MyDrive/fluor_models/training_data/merged_train_abs.csv\n",
      "\n",
      "‚úÖ em: 16833 existing + 112 new = 16945 total\n",
      "   ‚Üí /content/drive/MyDrive/fluor_models/training_data/merged_train_em.csv\n",
      "\n",
      "‚úÖ plqy: 12998 existing + 10 new = 13008 total\n",
      "   ‚Üí /content/drive/MyDrive/fluor_models/training_data/merged_train_plqy.csv\n",
      "\n",
      "‚úÖ k: 6976 existing + 74 new = 7050 total\n",
      "   ‚Üí /content/drive/MyDrive/fluor_models/training_data/merged_train_k.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Merge New Data with Existing Training Data\n",
    "# ============================================================================\n",
    "\n",
    "MERGE_WITH_EXISTING = True  # Set to False to skip merging\n",
    "\n",
    "if MERGE_WITH_EXISTING:\n",
    "    print(\"üîÄ Merging new data with existing training data...\\n\")\n",
    "    \n",
    "    for target in ['abs', 'em', 'plqy', 'k']:\n",
    "        # Paths\n",
    "        existing_main = os.path.join(DATA_DIR, f'train_{target}.csv')\n",
    "        existing_smiles = os.path.join(DATA_DIR, f'train_smiles_{target}.csv')\n",
    "        existing_solvent = os.path.join(DATA_DIR, f'train_sol_{target}.csv')\n",
    "        \n",
    "        new_main = os.path.join(OUTPUT_DIR, f'new_train_{target}.csv')\n",
    "        new_smiles = os.path.join(OUTPUT_DIR, f'new_train_smiles_{target}.csv')\n",
    "        new_solvent = os.path.join(OUTPUT_DIR, f'new_train_sol_{target}.csv')\n",
    "        \n",
    "        # Check if new data exists\n",
    "        if not os.path.exists(new_main):\n",
    "            print(f\"‚ö†Ô∏è  {target}: No new data to merge\")\n",
    "            continue\n",
    "        \n",
    "        # Load existing data\n",
    "        existing_main_df = pd.read_csv(existing_main)\n",
    "        existing_smiles_df = pd.read_csv(existing_smiles)\n",
    "        existing_solvent_df = pd.read_csv(existing_solvent)\n",
    "        \n",
    "        # Load new data\n",
    "        new_main_df = pd.read_csv(new_main)\n",
    "        new_smiles_df = pd.read_csv(new_smiles)\n",
    "        new_solvent_df = pd.read_csv(new_solvent)\n",
    "        \n",
    "        # Rename columns to match existing format\n",
    "        new_smiles_df.columns = existing_smiles_df.columns\n",
    "        new_solvent_df.columns = existing_solvent_df.columns\n",
    "        \n",
    "        # Concatenate\n",
    "        merged_main = pd.concat([existing_main_df, new_main_df], ignore_index=True)\n",
    "        merged_smiles = pd.concat([existing_smiles_df, new_smiles_df], ignore_index=True)\n",
    "        merged_solvent = pd.concat([existing_solvent_df, new_solvent_df], ignore_index=True)\n",
    "        \n",
    "        # Save merged files\n",
    "        merged_main_path = os.path.join(OUTPUT_DIR, f'merged_train_{target}.csv')\n",
    "        merged_smiles_path = os.path.join(OUTPUT_DIR, f'merged_train_smiles_{target}.csv')\n",
    "        merged_solvent_path = os.path.join(OUTPUT_DIR, f'merged_train_sol_{target}.csv')\n",
    "        \n",
    "        merged_main.to_csv(merged_main_path, index=False)\n",
    "        merged_smiles.to_csv(merged_smiles_path, index=False)\n",
    "        merged_solvent.to_csv(merged_solvent_path, index=False)\n",
    "        \n",
    "        print(f\"‚úÖ {target}: {len(existing_main_df)} existing + {len(new_main_df)} new = {len(merged_main)} total\")\n",
    "        print(f\"   ‚Üí {merged_main_path}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Skipping merge with existing data (MERGE_WITH_EXISTING=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f9cb87",
   "metadata": {},
   "source": [
    "## 10. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a6d8533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üìÇ Output directory: /content/drive/MyDrive/fluor_models/training_data\n",
      "\n",
      "üìÅ Files created:\n",
      "   ‚Ä¢ merged_train_abs.csv: 22062 rows, 9612.7 KB\n",
      "   ‚Ä¢ merged_train_em.csv: 16945 rows, 7386.9 KB\n",
      "   ‚Ä¢ merged_train_k.csv: 7050 rows, 3114.5 KB\n",
      "   ‚Ä¢ merged_train_plqy.csv: 13008 rows, 5712.1 KB\n",
      "   ‚Ä¢ merged_train_smiles_abs.csv: 22062 rows, 44127.9 KB\n",
      "   ‚Ä¢ merged_train_smiles_em.csv: 16945 rows, 33893.9 KB\n",
      "   ‚Ä¢ merged_train_smiles_k.csv: 7050 rows, 14103.9 KB\n",
      "   ‚Ä¢ merged_train_smiles_plqy.csv: 13008 rows, 26019.9 KB\n",
      "   ‚Ä¢ merged_train_sol_abs.csv: 22062 rows, 44127.9 KB\n",
      "   ‚Ä¢ merged_train_sol_em.csv: 16945 rows, 33893.9 KB\n",
      "   ‚Ä¢ merged_train_sol_k.csv: 7050 rows, 14103.9 KB\n",
      "   ‚Ä¢ merged_train_sol_plqy.csv: 13008 rows, 26019.9 KB\n",
      "   ‚Ä¢ new_train_abs.csv: 114 rows, 51.1 KB\n",
      "   ‚Ä¢ new_train_em.csv: 112 rows, 50.3 KB\n",
      "   ‚Ä¢ new_train_k.csv: 74 rows, 34.6 KB\n",
      "   ‚Ä¢ new_train_plqy.csv: 10 rows, 6.0 KB\n",
      "   ‚Ä¢ new_train_smiles_abs.csv: 114 rows, 241.9 KB\n",
      "   ‚Ä¢ new_train_smiles_em.csv: 112 rows, 237.9 KB\n",
      "   ‚Ä¢ new_train_smiles_k.csv: 74 rows, 161.9 KB\n",
      "   ‚Ä¢ new_train_smiles_plqy.csv: 10 rows, 33.9 KB\n",
      "   ‚Ä¢ new_train_sol_abs.csv: 114 rows, 238.9 KB\n",
      "   ‚Ä¢ new_train_sol_em.csv: 112 rows, 234.9 KB\n",
      "   ‚Ä¢ new_train_sol_k.csv: 74 rows, 158.9 KB\n",
      "   ‚Ä¢ new_train_sol_plqy.csv: 10 rows, 30.9 KB\n",
      "\n",
      "======================================================================\n",
      "üìã NEXT STEPS\n",
      "======================================================================\n",
      "\n",
      "To use this data for training:\n",
      "\n",
      "1. **Option A: Use merged data (recommended)**\n",
      "   - Copy merged_train_*.csv files to replace the original train_*.csv\n",
      "   - This combines your new data with the original ~22k samples\n",
      "   - Run the training notebook with the merged data\n",
      "\n",
      "2. **Option B: Fine-tune on new data only**\n",
      "   - Use new_train_*.csv files directly\n",
      "   - Start from pretrained models and fine-tune\n",
      "   - Smaller dataset may lead to overfitting\n",
      "\n",
      "3. **Update training notebook paths:**\n",
      "   In Fluor_RLAT_Training.ipynb, change DATA_DIR to:\n",
      "   DATA_DIR = '/content/drive/MyDrive/fluor_models/training_data'\n",
      "   \n",
      "   And use the merged files:\n",
      "   train_df = pd.read_csv(f'{DATA_DIR}/merged_train_{target}.csv')\n",
      "\n",
      "\n",
      "‚úÖ Done!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Summary\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìÇ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nüìÅ Files created:\")\n",
    "\n",
    "for f in sorted(os.listdir(OUTPUT_DIR)):\n",
    "    fpath = os.path.join(OUTPUT_DIR, f)\n",
    "    size = os.path.getsize(fpath)\n",
    "    rows = len(pd.read_csv(fpath)) if f.endswith('.csv') else 0\n",
    "    print(f\"   ‚Ä¢ {f}: {rows} rows, {size/1024:.1f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã NEXT STEPS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "To use this data for training:\n",
    "\n",
    "1. **Option A: Use merged data (recommended)**\n",
    "   - Copy merged_train_*.csv files to replace the original train_*.csv\n",
    "   - This combines your new data with the original ~22k samples\n",
    "   - Run the training notebook with the merged data\n",
    "\n",
    "2. **Option B: Fine-tune on new data only**\n",
    "   - Use new_train_*.csv files directly\n",
    "   - Start from pretrained models and fine-tune\n",
    "   - Smaller dataset may lead to overfitting\n",
    "\n",
    "3. **Update training notebook paths:**\n",
    "   In Fluor_RLAT_Training.ipynb, change DATA_DIR to:\n",
    "   DATA_DIR = '/content/drive/MyDrive/fluor_models/training_data'\n",
    "   \n",
    "   And use the merged files:\n",
    "   train_df = pd.read_csv(f'{DATA_DIR}/merged_train_{target}.csv')\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úÖ Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29afb47",
   "metadata": {},
   "source": [
    "## 11. Deploy to Fluor-RLAT Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54042f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ DEPLOYING MERGED DATA TO FLUOR-RLAT\n",
      "======================================================================\n",
      "\n",
      "üìÇ Source: /content/drive/MyDrive/fluor_models/training_data\n",
      "üìÇ Target: ./fluor_tools/Fluor-RLAT/data\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "üì¶ BACKUP (existing files renamed to *.bak)\n",
      "----------------------------------------------------------------------\n",
      "   ‚úì train_abs.csv ‚Üí train_abs.csv.bak\n",
      "   ‚úì train_em.csv ‚Üí train_em.csv.bak\n",
      "   ‚úì train_plqy.csv ‚Üí train_plqy.csv.bak\n",
      "   ‚úì train_k.csv ‚Üí train_k.csv.bak\n",
      "   ‚úì train_smiles_abs.csv ‚Üí train_smiles_abs.csv.bak\n",
      "   ‚úì train_smiles_em.csv ‚Üí train_smiles_em.csv.bak\n",
      "   ‚úì train_smiles_plqy.csv ‚Üí train_smiles_plqy.csv.bak\n",
      "   ‚úì train_smiles_k.csv ‚Üí train_smiles_k.csv.bak\n",
      "   ‚úì train_sol_abs.csv ‚Üí train_sol_abs.csv.bak\n",
      "   ‚úì train_sol_em.csv ‚Üí train_sol_em.csv.bak\n",
      "   ‚úì train_sol_plqy.csv ‚Üí train_sol_plqy.csv.bak\n",
      "   ‚úì train_sol_k.csv ‚Üí train_sol_k.csv.bak\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "üì§ DEPLOYED (merged files copied)\n",
      "----------------------------------------------------------------------\n",
      "   ‚úì merged_train_abs.csv ‚Üí train_abs.csv\n",
      "   ‚úì merged_train_em.csv ‚Üí train_em.csv\n",
      "   ‚úì merged_train_plqy.csv ‚Üí train_plqy.csv\n",
      "   ‚úì merged_train_k.csv ‚Üí train_k.csv\n",
      "   ‚úì merged_train_smiles_abs.csv ‚Üí train_smiles_abs.csv\n",
      "   ‚úì merged_train_smiles_em.csv ‚Üí train_smiles_em.csv\n",
      "   ‚úì merged_train_smiles_plqy.csv ‚Üí train_smiles_plqy.csv\n",
      "   ‚úì merged_train_smiles_k.csv ‚Üí train_smiles_k.csv\n",
      "   ‚úì merged_train_sol_abs.csv ‚Üí train_sol_abs.csv\n",
      "   ‚úì merged_train_sol_em.csv ‚Üí train_sol_em.csv\n",
      "   ‚úì merged_train_sol_plqy.csv ‚Üí train_sol_plqy.csv\n",
      "   ‚úì merged_train_sol_k.csv ‚Üí train_sol_k.csv\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Deployment complete! 12 files deployed, 12 backed up\n",
      "======================================================================\n",
      "\n",
      "üìä Verification - New training data sizes:\n",
      "   ‚Ä¢ train_abs.csv: 22062 rows\n",
      "   ‚Ä¢ train_em.csv: 16945 rows\n",
      "   ‚Ä¢ train_plqy.csv: 13008 rows\n",
      "   ‚Ä¢ train_k.csv: 7050 rows\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Deploy merged data to Fluor-RLAT data directory\n",
    "# ============================================================================\n",
    "# This cell backs up existing files and copies the merged training data\n",
    "# to the Fluor-RLAT/data directory for training\n",
    "\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Target directory (cloned repo's data folder)\n",
    "TARGET_DIR = DATA_DIR  # './fluor_tools/Fluor-RLAT/data'\n",
    "\n",
    "# Files to deploy (merged files ‚Üí train files)\n",
    "DEPLOY_FILES = {\n",
    "    'merged_train_abs.csv': 'train_abs.csv',\n",
    "    'merged_train_em.csv': 'train_em.csv',\n",
    "    'merged_train_plqy.csv': 'train_plqy.csv',\n",
    "    'merged_train_k.csv': 'train_k.csv',\n",
    "    'merged_train_smiles_abs.csv': 'train_smiles_abs.csv',\n",
    "    'merged_train_smiles_em.csv': 'train_smiles_em.csv',\n",
    "    'merged_train_smiles_plqy.csv': 'train_smiles_plqy.csv',\n",
    "    'merged_train_smiles_k.csv': 'train_smiles_k.csv',\n",
    "    'merged_train_sol_abs.csv': 'train_sol_abs.csv',\n",
    "    'merged_train_sol_em.csv': 'train_sol_em.csv',\n",
    "    'merged_train_sol_plqy.csv': 'train_sol_plqy.csv',\n",
    "    'merged_train_sol_k.csv': 'train_sol_k.csv',\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üöÄ DEPLOYING MERGED DATA TO FLUOR-RLAT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìÇ Source: {OUTPUT_DIR}\")\n",
    "print(f\"üìÇ Target: {TARGET_DIR}\")\n",
    "\n",
    "# Timestamp for backup suffix\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "backed_up = []\n",
    "deployed = []\n",
    "skipped = []\n",
    "\n",
    "for source_name, target_name in DEPLOY_FILES.items():\n",
    "    source_path = os.path.join(OUTPUT_DIR, source_name)\n",
    "    target_path = os.path.join(TARGET_DIR, target_name)\n",
    "    backup_path = os.path.join(TARGET_DIR, f\"{target_name}.bak\")\n",
    "    \n",
    "    # Check if source file exists\n",
    "    if not os.path.exists(source_path):\n",
    "        skipped.append(f\"{source_name} (source not found)\")\n",
    "        continue\n",
    "    \n",
    "    # If target exists, back it up\n",
    "    if os.path.exists(target_path):\n",
    "        # If .bak already exists, rename with timestamp\n",
    "        if os.path.exists(backup_path):\n",
    "            backup_path = os.path.join(TARGET_DIR, f\"{target_name}.bak.{timestamp}\")\n",
    "        \n",
    "        shutil.move(target_path, backup_path)\n",
    "        backed_up.append(f\"{target_name} ‚Üí {os.path.basename(backup_path)}\")\n",
    "    \n",
    "    # Copy the merged file to target\n",
    "    shutil.copy2(source_path, target_path)\n",
    "    deployed.append(f\"{source_name} ‚Üí {target_name}\")\n",
    "\n",
    "# Report\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"üì¶ BACKUP (existing files renamed to *.bak)\")\n",
    "print(\"-\" * 70)\n",
    "if backed_up:\n",
    "    for item in backed_up:\n",
    "        print(f\"   ‚úì {item}\")\n",
    "else:\n",
    "    print(\"   (no existing files to backup)\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"üì§ DEPLOYED (merged files copied)\")\n",
    "print(\"-\" * 70)\n",
    "if deployed:\n",
    "    for item in deployed:\n",
    "        print(f\"   ‚úì {item}\")\n",
    "else:\n",
    "    print(\"   (no files deployed)\")\n",
    "\n",
    "if skipped:\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"‚ö†Ô∏è  SKIPPED\")\n",
    "    print(\"-\" * 70)\n",
    "    for item in skipped:\n",
    "        print(f\"   ‚Ä¢ {item}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"‚úÖ Deployment complete! {len(deployed)} files deployed, {len(backed_up)} backed up\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verify deployment\n",
    "print(\"\\nüìä Verification - New training data sizes:\")\n",
    "for target_name in ['train_abs.csv', 'train_em.csv', 'train_plqy.csv', 'train_k.csv']:\n",
    "    target_path = os.path.join(TARGET_DIR, target_name)\n",
    "    if os.path.exists(target_path):\n",
    "        rows = len(pd.read_csv(target_path))\n",
    "        print(f\"   ‚Ä¢ {target_name}: {rows} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec063f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
