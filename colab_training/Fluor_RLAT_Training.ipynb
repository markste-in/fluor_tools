{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd601f7",
   "metadata": {},
   "source": [
    "# üî¨ Fluor-RLAT Model Training\n",
    "\n",
    "Train property prediction models for fluorescent molecules on Google Colab with GPU acceleration.\n",
    "\n",
    "**Quick Start:**\n",
    "1. Go to Runtime ‚Üí Change runtime type ‚Üí Select **T4 GPU**\n",
    "2. Run all cells (Runtime ‚Üí Run all)\n",
    "3. The notebook will automatically clone the repository and download training data\n",
    "\n",
    "**Models:**\n",
    "- `abs` - Absorption wavelength (nm)\n",
    "- `em` - Emission wavelength (nm)\n",
    "- `plqy` - Photoluminescence quantum yield (0-1)\n",
    "- `k` - Log molar absorptivity\n",
    "\n",
    "**Architecture:** AttentiveFP GNN + Fingerprint CNN fusion (~2.3M parameters per model)\n",
    "\n",
    "**Expected training time:** ~1-2 hours total on T4 GPU\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c5fdf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU: Tesla T4\n",
      "‚úÖ Torch dynamo disabled\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CRITICAL: Disable torch dynamo BEFORE importing torch\n",
    "# This prevents version conflicts between Colab's PyTorch and DGL\n",
    "# ============================================================================\n",
    "import os\n",
    "os.environ['TORCHDYNAMO_DISABLE'] = '1'\n",
    "\n",
    "import torch\n",
    "\n",
    "# Also disable dynamo via config (belt and suspenders)\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "torch._dynamo.config.disable = True\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"‚úÖ Torch dynamo disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63a9cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected CUDA version: 12.1\n",
      "Installing RDKit...\n",
      "Installing DGL for CUDA 12.x...\n",
      "Installing dgllife...\n",
      "\n",
      "‚úÖ Dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "# Install DGL, dgllife, and RDKit (Colab has PyTorch pre-installed)\n",
    "# DGL wheel selection based on CUDA version\n",
    "\n",
    "cuda_version = torch.version.cuda\n",
    "print(f\"Detected CUDA version: {cuda_version}\")\n",
    "\n",
    "# Install RDKit first (required by dgllife)\n",
    "print(\"Installing RDKit...\")\n",
    "!pip install rdkit -q\n",
    "\n",
    "# Install DGL for the appropriate CUDA version\n",
    "if cuda_version and cuda_version.startswith('12'):\n",
    "    print(\"Installing DGL for CUDA 12.x...\")\n",
    "    !pip install dgl -f https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html -q\n",
    "elif cuda_version and cuda_version.startswith('11'):\n",
    "    print(\"Installing DGL for CUDA 11.x...\")\n",
    "    !pip install dgl -f https://data.dgl.ai/wheels/torch-2.1/cu118/repo.html -q\n",
    "else:\n",
    "    # Fallback - try latest\n",
    "    print(\"Installing DGL (default)...\")\n",
    "    !pip install dgl -f https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html -q\n",
    "\n",
    "# Install dgllife for molecular graph utilities\n",
    "print(\"Installing dgllife...\")\n",
    "!pip install dgllife -q\n",
    "\n",
    "# Install tqdm for progress bars (usually present but ensure it's available)\n",
    "!pip install tqdm -q\n",
    "\n",
    "print(\"\\n‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb4113f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGL version: 2.4.0+cu124\n",
      "DGL graph on CUDA: cuda:0\n",
      "‚úÖ DGL CUDA support working!\n"
     ]
    }
   ],
   "source": [
    "# Verify DGL installation\n",
    "import dgl\n",
    "print(f\"DGL version: {dgl.__version__}\")\n",
    "\n",
    "# Test CUDA with DGL\n",
    "if torch.cuda.is_available():\n",
    "    g = dgl.graph(([0, 1], [1, 2]))\n",
    "    g = g.to('cuda')\n",
    "    print(f\"DGL graph on CUDA: {g.device}\")\n",
    "    print(\"‚úÖ DGL CUDA support working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21864423",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive and Setup Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "783c6577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "‚úÖ Directories created\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directories\n",
    "import os\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "os.makedirs('./checkpoints', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155c79d",
   "metadata": {},
   "source": [
    "## 3. Clone Repository and Setup Data\n",
    "\n",
    "Clone the fluor_tools repository directly from GitHub to access training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bafa7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Repository already exists at fluor_tools\n",
      "Already up to date.\n",
      "üìÅ Data directory: ./fluor_tools/Fluor-RLAT/data\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "import os\n",
    "\n",
    "REPO_URL = \"https://github.com/markste-in/fluor_tools.git\"\n",
    "REPO_DIR = \"fluor_tools\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(f\"üì• Cloning repository from {REPO_URL}...\")\n",
    "    !git clone {REPO_URL}\n",
    "    print(\"‚úÖ Repository cloned!\")\n",
    "else:\n",
    "    print(f\"‚úÖ Repository already exists at {REPO_DIR}\")\n",
    "    # Optionally pull latest changes\n",
    "    !cd {REPO_DIR} && git pull\n",
    "\n",
    "# Set data path to the cloned repo\n",
    "DATA_DIR = f'./{REPO_DIR}/Fluor-RLAT/data'\n",
    "print(f\"üìÅ Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594d8c8",
   "metadata": {},
   "source": [
    "## 4. Verify GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46da78ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 16 11:03:33 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   75C    P0             30W /   70W |     325MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            4642      C   /usr/bin/python3                        218MiB |\n",
      "|    0   N/A  N/A           43660      C   /usr/bin/python3                        104MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "üñ•Ô∏è Using device: cuda\n",
      "   GPU: Tesla T4\n",
      "   Memory: 15.6 GB\n",
      "   Compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Check GPU details\n",
    "!nvidia-smi\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"\\nüñ•Ô∏è Using device: {device}\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"   Memory: {props.total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"   Compute capability: {props.major}.{props.minor}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected! Training will be slow.\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9310c65",
   "metadata": {},
   "source": [
    "## 5. Configure Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c232f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment configured\n"
     ]
    }
   ],
   "source": [
    "# Configure CUDA memory management to prevent OOM errors\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    # Enable TF32 for faster training on Ampere GPUs (A100)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "print(\"‚úÖ Environment configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d14da8",
   "metadata": {},
   "source": [
    "## 6. Load and Verify Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54013c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data files in: ./fluor_tools/Fluor-RLAT/data\n",
      "\n",
      "‚úÖ Found 24 files:\n",
      "   train_abs.csv (9.3 MB)\n",
      "   train_smiles_abs.csv (42.9 MB)\n",
      "   train_sol_abs.csv (42.9 MB)\n",
      "   train_em.csv (7.2 MB)\n",
      "   train_smiles_em.csv (32.9 MB)\n",
      "   train_sol_em.csv (32.9 MB)\n",
      "   ... and 18 more\n",
      "\n",
      "‚úÖ All required files present!\n"
     ]
    }
   ],
   "source": [
    "# Verify data files are present\n",
    "DATA_DIR = './fluor_tools/Fluor-RLAT/data'\n",
    "\n",
    "required_base = ['train', 'valid']\n",
    "targets = ['abs', 'em', 'plqy', 'k']\n",
    "file_types = ['', '_smiles', '_sol']\n",
    "\n",
    "print(f\"Checking data files in: {DATA_DIR}\")\n",
    "missing = []\n",
    "found = []\n",
    "\n",
    "for base in required_base:\n",
    "    for target in targets:\n",
    "        for ftype in file_types:\n",
    "            filename = f'{base}{ftype}_{target}.csv'\n",
    "            path = os.path.join(DATA_DIR, filename)\n",
    "            if os.path.exists(path):\n",
    "                size = os.path.getsize(path) / 1024 / 1024\n",
    "                found.append((filename, size))\n",
    "            else:\n",
    "                missing.append(filename)\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(found)} files:\")\n",
    "for fname, size in found[:6]:\n",
    "    print(f\"   {fname} ({size:.1f} MB)\")\n",
    "if len(found) > 6:\n",
    "    print(f\"   ... and {len(found) - 6} more\")\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\n‚ùå Missing {len(missing)} files:\")\n",
    "    for fname in missing[:5]:\n",
    "        print(f\"   {fname}\")\n",
    "    print(\"\\n‚ö†Ô∏è Please upload data before training!\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All required files present!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e0f8864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "  ABS: 21,948 train / 3,132 valid\n",
      "  EM: 16,833 train / 2,370 valid\n",
      "  PLQY: 12,998 train / 1,855 valid\n",
      "  K: 6,976 train / 952 valid\n"
     ]
    }
   ],
   "source": [
    "# Load sample counts\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Dataset sizes:\")\n",
    "for target in ['abs', 'em', 'plqy', 'k']:\n",
    "    train_path = os.path.join(DATA_DIR, f'train_{target}.csv')\n",
    "    valid_path = os.path.join(DATA_DIR, f'valid_{target}.csv')\n",
    "    \n",
    "    if os.path.exists(train_path) and os.path.exists(valid_path):\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        valid_df = pd.read_csv(valid_path)\n",
    "        print(f\"  {target.upper()}: {len(train_df):,} train / {len(valid_df):,} valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde5973",
   "metadata": {},
   "source": [
    "## 7. Initialize Model Architecture\n",
    "\n",
    "Define the complete model architecture including:\n",
    "- AttentiveFP Graph Neural Network\n",
    "- Fingerprint CNN with attention (for abs/em)\n",
    "- Simple FC network (for plqy/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb2c27d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import copy\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Use tqdm.auto which automatically selects the right backend\n",
    "# Falls back to text mode if notebook widgets aren't available\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import dgl\n",
    "from dgllife.model.gnn import AttentiveFPGNN\n",
    "from dgllife.model.readout import AttentiveFPReadout\n",
    "from dgllife.utils import (\n",
    "    smiles_to_bigraph,\n",
    "    AttentiveFPAtomFeaturizer,\n",
    "    AttentiveFPBondFeaturizer,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "554d72aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n",
      "   Learning rate: 0.0005\n",
      "   LR scheduler: Enabled\n",
      "      Factor: 0.5, Patience: 10, Min LR: 1e-06\n",
      "   abs/em: GraphFingerprintsModel (num_layers=2/3, num_timesteps=2/1)\n",
      "   plqy/k: GraphFingerprintsModelFC (num_layers=2/3, num_timesteps=3/1)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Configuration\n",
    "# ============================================================================\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-4  # Reduced from 1e-3 for more stable training\n",
    "GRAPH_FEAT_SIZE = 256\n",
    "\n",
    "# Learning rate scheduler settings\n",
    "USE_LR_SCHEDULER = True   # Set to False to disable scheduler\n",
    "LR_SCHEDULER_FACTOR = 0.5  # Reduce LR by this factor when plateau\n",
    "LR_SCHEDULER_PATIENCE = 10  # Epochs to wait before reducing LR\n",
    "LR_SCHEDULER_MIN = 1e-6   # Minimum learning rate\n",
    "\n",
    "# Model configurations per target (MATCHES pretrained model parameters)\n",
    "# Verified from 02_property_prediction.py source code\n",
    "MODEL_CONFIGS = {\n",
    "    'abs': {\n",
    "        'num_layers': 2,\n",
    "        'num_timesteps': 2,\n",
    "        'dropout': 0.3,\n",
    "        'alpha': 0.1,  # LDS alpha\n",
    "        'model_class': 'GraphFingerprintsModel',  # CNN attention + solvent extractor\n",
    "    },\n",
    "    'em': {\n",
    "        'num_layers': 3,\n",
    "        'num_timesteps': 1,\n",
    "        'dropout': 0.3,\n",
    "        'alpha': 0.0,\n",
    "        'model_class': 'GraphFingerprintsModel',\n",
    "    },\n",
    "    'plqy': {\n",
    "        'num_layers': 2,\n",
    "        'num_timesteps': 3,\n",
    "        'dropout': 0.4,\n",
    "        'alpha': 0.2,\n",
    "        'model_class': 'GraphFingerprintsModelFC',  # Simple FC for all fingerprints\n",
    "    },\n",
    "    'k': {\n",
    "        'num_layers': 3,\n",
    "        'num_timesteps': 1,\n",
    "        'dropout': 0.3,\n",
    "        'alpha': 0.6,\n",
    "        'model_class': 'GraphFingerprintsModelFC',\n",
    "    },\n",
    "}\n",
    "\n",
    "# Featurizers for molecular graphs\n",
    "ATOM_FEATURIZER = AttentiveFPAtomFeaturizer(atom_data_field='hv')\n",
    "BOND_FEATURIZER = AttentiveFPBondFeaturizer(bond_data_field='he')\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"   LR scheduler: {'Enabled' if USE_LR_SCHEDULER else 'Disabled'}\")\n",
    "if USE_LR_SCHEDULER:\n",
    "    print(f\"      Factor: {LR_SCHEDULER_FACTOR}, Patience: {LR_SCHEDULER_PATIENCE}, Min LR: {LR_SCHEDULER_MIN}\")\n",
    "print(\"   abs/em: GraphFingerprintsModel (num_layers=2/3, num_timesteps=2/1)\")\n",
    "print(\"   plqy/k: GraphFingerprintsModelFC (num_layers=2/3, num_timesteps=3/1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b075e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model classes defined (matching original 02_property_prediction.py)\n",
      "   - GraphFingerprintsModel (alias: GraphFingerprintsModelAttentionCNN): for abs/em\n",
      "   - GraphFingerprintsModelFC (alias: GraphFingerprintsModelSimpleFC): for plqy/k\n",
      "\n",
      "   Architecture summary:\n",
      "   abs/em:  fp_extractor (CNN) + solvent_extractor (FC) -> predict(1024->128->1)\n",
      "   plqy/k:  fp_fc (FC, all fingerprints combined) -> predict(512->128->1)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Model Architecture Classes\n",
    "# ============================================================================\n",
    "# These MUST match the original architecture in 02_property_prediction.py\n",
    "# to ensure compatibility with pretrained models and consistent results.\n",
    "#\n",
    "# VERIFIED against pretrained model state_dicts:\n",
    "# - Model_abs.pth, Model_em.pth: use fp_extractor + solvent_extractor\n",
    "# - Model_plqy.pth, Model_k.pth: use fp_fc only (no solvent split)\n",
    "\n",
    "class FingerprintAttentionCNN(nn.Module):\n",
    "    \"\"\"CNN with attention for fingerprint processing (used by abs/em models).\n",
    "    \n",
    "    Layer names must match: fp_extractor.conv_feat, fp_extractor.conv_attn\n",
    "    Output: 2 * conv_channels (512 when conv_channels=256)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, conv_channels=256):\n",
    "        super().__init__()\n",
    "        self.conv_feat = nn.Conv1d(1, conv_channels, kernel_size=3, padding=1)\n",
    "        self.conv_attn = nn.Conv1d(1, conv_channels, kernel_size=3, padding=1)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # [B, 1, D]\n",
    "        feat_map = self.conv_feat(x)         # [B, C, D]\n",
    "        attn_map = self.conv_attn(x)         # [B, C, D]\n",
    "        attn_weights = self.softmax(attn_map)\n",
    "        attn_out = torch.sum(feat_map * attn_weights, dim=-1)  # [B, C]\n",
    "        pooled = self.pool(feat_map).squeeze(-1)               # [B, C]\n",
    "        return torch.cat([attn_out, pooled], dim=1)            # [B, 2C]\n",
    "\n",
    "\n",
    "class GraphFingerprintsModel(nn.Module):\n",
    "    \"\"\"Model for abs/em: AttentiveFP GNN + CNN attention for fingerprints.\n",
    "    \n",
    "    This is the ORIGINAL class name from 02_property_prediction.py.\n",
    "    Used for absorption and emission prediction.\n",
    "    \n",
    "    Layer names verified against Model_abs.pth / Model_em.pth:\n",
    "    - gnn.*, readout.*: AttentiveFP layers\n",
    "    - fp_extractor.conv_feat, fp_extractor.conv_attn: CNN attention\n",
    "    - solvent_extractor.0, solvent_extractor.3: FC for solvent (1024->256->256)\n",
    "    - predict.1, predict.3: final prediction (1024->128->1)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, node_feat_size, edge_feat_size, solvent_dim, smiles_extra_dim,\n",
    "                 graph_feat_size=256, num_layers=2, num_timesteps=2, n_tasks=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.solvent_dim = solvent_dim\n",
    "        \n",
    "        # GNN\n",
    "        self.gnn = AttentiveFPGNN(\n",
    "            node_feat_size=node_feat_size,\n",
    "            edge_feat_size=edge_feat_size,\n",
    "            num_layers=num_layers,\n",
    "            graph_feat_size=graph_feat_size,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.readout = AttentiveFPReadout(\n",
    "            feat_size=graph_feat_size,\n",
    "            num_timesteps=num_timesteps,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Fingerprint part: smiles + extra -> CNN attention -> 2*graph_feat_size\n",
    "        self.fp_extractor = FingerprintAttentionCNN(smiles_extra_dim, conv_channels=graph_feat_size)\n",
    "        \n",
    "        # Fingerprint part: solvent -> FC -> graph_feat_size\n",
    "        # Original: nn.Linear(solvent_dim, 256), ReLU, Dropout, nn.Linear(256, graph_feat_size)\n",
    "        self.solvent_extractor = nn.Sequential(\n",
    "            nn.Linear(solvent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, graph_feat_size)\n",
    "        )\n",
    "        \n",
    "        # Prediction: graph(256) + solvent(256) + fp(512) = 1024 -> 128 -> 1\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(graph_feat_size * 4, 128),  # 1024\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_tasks)\n",
    "        )\n",
    "        \n",
    "    def forward(self, graph, node_feats, edge_feats, fingerprints):\n",
    "        node_out = self.gnn(graph, node_feats, edge_feats)\n",
    "        graph_out = self.readout(graph, node_out, False)\n",
    "        \n",
    "        solvent_feat = fingerprints[:, :self.solvent_dim]\n",
    "        smiles_extra_feat = fingerprints[:, self.solvent_dim:]\n",
    "        \n",
    "        solvent_out = self.solvent_extractor(solvent_feat)\n",
    "        smiles_extra_out = self.fp_extractor(smiles_extra_feat)\n",
    "        \n",
    "        combined = torch.cat([graph_out, solvent_out, smiles_extra_out], dim=1)\n",
    "        return self.predict(combined)\n",
    "\n",
    "\n",
    "class GraphFingerprintsModelFC(nn.Module):\n",
    "    \"\"\"Model for plqy/k: AttentiveFP GNN + Simple FC for fingerprints.\n",
    "    \n",
    "    This uses a different architecture from abs/em - processes ALL fingerprints\n",
    "    together through a simple FC, no separate solvent extractor.\n",
    "    \n",
    "    Layer names verified against Model_plqy.pth / Model_k.pth:\n",
    "    - gnn.*, readout.*: AttentiveFP layers\n",
    "    - fp_fc.0, fp_fc.3: FC for all fingerprints (2192->256->256)\n",
    "    - predict.1, predict.3: final prediction (512->128->1)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, node_feat_size, edge_feat_size, fp_size,\n",
    "                 graph_feat_size=256, num_layers=2, num_timesteps=2, n_tasks=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # GNN\n",
    "        self.gnn = AttentiveFPGNN(\n",
    "            node_feat_size=node_feat_size,\n",
    "            edge_feat_size=edge_feat_size,\n",
    "            num_layers=num_layers,\n",
    "            graph_feat_size=graph_feat_size,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.readout = AttentiveFPReadout(\n",
    "            feat_size=graph_feat_size,\n",
    "            num_timesteps=num_timesteps,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # FC for ALL fingerprints -> graph_feat_size\n",
    "        # Original: Linear(fp_size, 256), ReLU, Dropout, Linear(256, graph_feat_size)\n",
    "        # Indices: 0=Linear, 1=ReLU, 2=Dropout, 3=Linear\n",
    "        self.fp_fc = nn.Sequential(\n",
    "            nn.Linear(fp_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, graph_feat_size)\n",
    "        )\n",
    "        \n",
    "        # Prediction: graph(256) + fp(256) = 512 -> 128 -> 1\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(graph_feat_size * 2, 128),  # 512\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_tasks)\n",
    "        )\n",
    "        \n",
    "    def forward(self, graph, node_feats, edge_feats, fingerprints):\n",
    "        node_out = self.gnn(graph, node_feats, edge_feats)\n",
    "        graph_out = self.readout(graph, node_out, False)\n",
    "        fp_out = self.fp_fc(fingerprints)\n",
    "        combined = torch.cat([graph_out, fp_out], dim=1)\n",
    "        return self.predict(combined)\n",
    "\n",
    "\n",
    "# Aliases to match different naming conventions\n",
    "GraphFingerprintsModelAttentionCNN = GraphFingerprintsModel  # for abs/em\n",
    "GraphFingerprintsModelSimpleFC = GraphFingerprintsModelFC     # for plqy/k\n",
    "\n",
    "print(\"‚úÖ Model classes defined (matching original 02_property_prediction.py)\")\n",
    "print(\"   - GraphFingerprintsModel (alias: GraphFingerprintsModelAttentionCNN): for abs/em\")\n",
    "print(\"   - GraphFingerprintsModelFC (alias: GraphFingerprintsModelSimpleFC): for plqy/k\")\n",
    "print(\"\")\n",
    "print(\"   Architecture summary:\")\n",
    "print(\"   abs/em:  fp_extractor (CNN) + solvent_extractor (FC) -> predict(1024->128->1)\")\n",
    "print(\"   plqy/k:  fp_fc (FC, all fingerprints combined) -> predict(512->128->1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a120063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Original model configs defined\n",
      "   abs/em use GraphFingerprintsModel (CNN attention + solvent extractor)\n",
      "   plqy/k use GraphFingerprintsModelFC (simple FC for all fingerprints)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Model Configs for Original Pretrained Models\n",
    "# ============================================================================\n",
    "# Verified hyperparameters from 02_property_prediction.py:\n",
    "#\n",
    "# abs:  num_layers=2, num_timesteps=2, dropout=0.3, alpha=0.1\n",
    "# em:   num_layers=3, num_timesteps=1, dropout=0.3, alpha=0.0  \n",
    "# plqy: num_layers=2, num_timesteps=3, dropout=0.4, alpha=0.2\n",
    "# k:    num_layers=3, num_timesteps=1, dropout=0.3, alpha=0.6\n",
    "\n",
    "ORIGINAL_MODEL_CONFIGS = {\n",
    "    'abs':  {'num_layers': 2, 'num_timesteps': 2, 'dropout': 0.3, 'alpha': 0.1, 'model_class': 'GraphFingerprintsModel'},\n",
    "    'em':   {'num_layers': 3, 'num_timesteps': 1, 'dropout': 0.3, 'alpha': 0.0, 'model_class': 'GraphFingerprintsModel'},\n",
    "    'plqy': {'num_layers': 2, 'num_timesteps': 3, 'dropout': 0.4, 'alpha': 0.2, 'model_class': 'GraphFingerprintsModelFC'},\n",
    "    'k':    {'num_layers': 3, 'num_timesteps': 1, 'dropout': 0.3, 'alpha': 0.6, 'model_class': 'GraphFingerprintsModelFC'},\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Original model configs defined\")\n",
    "print(\"   abs/em use GraphFingerprintsModel (CNN attention + solvent extractor)\")\n",
    "print(\"   plqy/k use GraphFingerprintsModelFC (simple FC for all fingerprints)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "178cee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset classes defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Dataset and Data Loading\n",
    "# ============================================================================\n",
    "\n",
    "class MolecularDataset(Dataset):\n",
    "    \"\"\"Dataset for molecular property prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, graphs, fingerprints, labels, masks=None, weights=None):\n",
    "        self.graphs = graphs\n",
    "        self.fingerprints = fingerprints\n",
    "        self.labels = labels\n",
    "        self.masks = masks\n",
    "        self.weights = weights\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.graphs[idx],\n",
    "            self.fingerprints[idx],\n",
    "            self.labels[idx],\n",
    "            self.masks[idx] if self.masks is not None else 1.0,\n",
    "            self.weights[idx] if self.weights is not None else 1.0\n",
    "        )\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for batching molecular graphs.\"\"\"\n",
    "    graphs, fps, labels, masks, weights = zip(*batch)\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    fps = torch.stack(fps)\n",
    "    labels = torch.stack(labels)\n",
    "    masks = torch.tensor(masks, dtype=torch.float32) if masks[0] is not None else None\n",
    "    weights = torch.tensor(weights, dtype=torch.float32) if weights[0] is not None else None\n",
    "    return batched_graph, fps, labels, masks, weights\n",
    "\n",
    "\n",
    "def compute_lds_weights(labels, alpha=0.5, kernel_size=5):\n",
    "    \"\"\"Compute Label Distribution Smoothing weights.\"\"\"\n",
    "    if alpha == 0:\n",
    "        return np.ones(len(labels))\n",
    "    \n",
    "    n_bins = 100\n",
    "    label_min, label_max = labels.min(), labels.max()\n",
    "    bins = np.linspace(label_min, label_max, n_bins + 1)\n",
    "    bin_indices = np.digitize(labels, bins) - 1\n",
    "    bin_indices = np.clip(bin_indices, 0, n_bins - 1)\n",
    "    \n",
    "    bin_counts = np.bincount(bin_indices, minlength=n_bins).astype(float)\n",
    "    kernel = np.ones(kernel_size) / kernel_size\n",
    "    smoothed_counts = np.convolve(bin_counts, kernel, mode='same')\n",
    "    smoothed_counts = np.maximum(smoothed_counts, 1)\n",
    "    \n",
    "    effective_counts = bin_counts ** alpha * smoothed_counts ** (1 - alpha)\n",
    "    effective_counts = np.maximum(effective_counts, 1)\n",
    "    \n",
    "    weights = 1.0 / effective_counts[bin_indices]\n",
    "    weights = weights / weights.mean()\n",
    "    \n",
    "    return weights.astype(np.float32)\n",
    "\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"Convert SMILES to DGL graph with AttentiveFP featurization.\"\"\"\n",
    "    try:\n",
    "        graph = smiles_to_bigraph(\n",
    "            smiles,\n",
    "            node_featurizer=ATOM_FEATURIZER,\n",
    "            edge_featurizer=BOND_FEATURIZER,\n",
    "            add_self_loop=False\n",
    "        )\n",
    "        return graph\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\"‚úÖ Dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6003ef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Data Loading Functions\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_process_data(target, data_dir, config):\n",
    "    \"\"\"Load and process training/validation data for a target property.\"\"\"\n",
    "    \n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # Load main data files\n",
    "    train_df = pd.read_csv(data_dir / f'train_{target}.csv')\n",
    "    valid_df = pd.read_csv(data_dir / f'valid_{target}.csv')\n",
    "    \n",
    "    # Load fingerprint files\n",
    "    train_smiles_fp = pd.read_csv(data_dir / f'train_smiles_{target}.csv')\n",
    "    train_sol_fp = pd.read_csv(data_dir / f'train_sol_{target}.csv')\n",
    "    valid_smiles_fp = pd.read_csv(data_dir / f'valid_smiles_{target}.csv')\n",
    "    valid_sol_fp = pd.read_csv(data_dir / f'valid_sol_{target}.csv')\n",
    "    \n",
    "    print(f\"   Train samples: {len(train_df)}\")\n",
    "    print(f\"   Valid samples: {len(valid_df)}\")\n",
    "    \n",
    "    # Extract labels\n",
    "    train_labels = train_df[target].values.reshape(-1, 1).astype(np.float32)\n",
    "    valid_labels = valid_df[target].values.reshape(-1, 1).astype(np.float32)\n",
    "    \n",
    "    # Normalize labels\n",
    "    scaler = StandardScaler()\n",
    "    train_labels_scaled = scaler.fit_transform(train_labels)\n",
    "    valid_labels_scaled = scaler.transform(valid_labels)\n",
    "    \n",
    "    # Extract and normalize numeric features\n",
    "    numeric_cols = train_df.columns[8:16].tolist() if len(train_df.columns) > 16 else []\n",
    "    \n",
    "    scaler_num = MinMaxScaler()\n",
    "    if numeric_cols:\n",
    "        train_numeric = scaler_num.fit_transform(train_df[numeric_cols].values)\n",
    "        valid_numeric = scaler_num.transform(valid_df[numeric_cols].values)\n",
    "    else:\n",
    "        train_numeric = np.zeros((len(train_df), 0))\n",
    "        valid_numeric = np.zeros((len(valid_df), 0))\n",
    "    \n",
    "    # Combine fingerprints\n",
    "    train_sol = train_sol_fp.values.astype(np.float32)\n",
    "    train_smiles = train_smiles_fp.values.astype(np.float32)\n",
    "    valid_sol = valid_sol_fp.values.astype(np.float32)\n",
    "    valid_smiles = valid_smiles_fp.values.astype(np.float32)\n",
    "    \n",
    "    # Get scaffold flags if present\n",
    "    scaffold_cols = [c for c in train_df.columns if c.startswith('fragment_')]\n",
    "    if scaffold_cols:\n",
    "        train_scaffold = train_df[scaffold_cols].values.astype(np.float32)\n",
    "        valid_scaffold = valid_df[scaffold_cols].values.astype(np.float32)\n",
    "    else:\n",
    "        train_scaffold = np.zeros((len(train_df), 0), dtype=np.float32)\n",
    "        valid_scaffold = np.zeros((len(valid_df), 0), dtype=np.float32)\n",
    "    \n",
    "    # Combine all features\n",
    "    train_fp = np.hstack([train_sol, train_smiles, train_numeric, train_scaffold])\n",
    "    valid_fp = np.hstack([valid_sol, valid_smiles, valid_numeric, valid_scaffold])\n",
    "    \n",
    "    solvent_dim = train_sol.shape[1]\n",
    "    smiles_extra_dim = train_fp.shape[1] - solvent_dim\n",
    "    fp_size = train_fp.shape[1]\n",
    "    \n",
    "    print(f\"   Total fingerprint dimensions: {fp_size}\")\n",
    "    \n",
    "    # Compute LDS weights\n",
    "    alpha = config['alpha']\n",
    "    train_weights = compute_lds_weights(train_labels.flatten(), alpha=alpha)\n",
    "    print(f\"   LDS alpha: {alpha}, weight range: [{train_weights.min():.2f}, {train_weights.max():.2f}]\")\n",
    "    \n",
    "    # Convert SMILES to graphs\n",
    "    print(\"   Converting SMILES to graphs...\")\n",
    "    \n",
    "    train_smiles_list = train_df['smiles'].tolist()\n",
    "    valid_smiles_list = valid_df['smiles'].tolist()\n",
    "    \n",
    "    train_graphs = []\n",
    "    for smi in tqdm(train_smiles_list, desc=\"   Train graphs\", leave=False):\n",
    "        g = smiles_to_graph(smi)\n",
    "        if g is None:\n",
    "            g = dgl.graph(([0], [0]))\n",
    "            g.ndata['hv'] = torch.zeros(1, 39)\n",
    "            g.edata['he'] = torch.zeros(1, 10)\n",
    "        train_graphs.append(g)\n",
    "    \n",
    "    valid_graphs = []\n",
    "    for smi in tqdm(valid_smiles_list, desc=\"   Valid graphs\", leave=False):\n",
    "        g = smiles_to_graph(smi)\n",
    "        if g is None:\n",
    "            g = dgl.graph(([0], [0]))\n",
    "            g.ndata['hv'] = torch.zeros(1, 39)\n",
    "            g.edata['he'] = torch.zeros(1, 10)\n",
    "        valid_graphs.append(g)\n",
    "    \n",
    "    print(f\"   ‚úÖ Converted {len(train_graphs)} train + {len(valid_graphs)} valid graphs\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_data = MolecularDataset(\n",
    "        graphs=train_graphs,\n",
    "        fingerprints=torch.tensor(train_fp, dtype=torch.float32),\n",
    "        labels=torch.tensor(train_labels_scaled, dtype=torch.float32),\n",
    "        masks=None,\n",
    "        weights=train_weights\n",
    "    )\n",
    "    \n",
    "    valid_data = MolecularDataset(\n",
    "        graphs=valid_graphs,\n",
    "        fingerprints=torch.tensor(valid_fp, dtype=torch.float32),\n",
    "        labels=torch.tensor(valid_labels_scaled, dtype=torch.float32),\n",
    "        masks=None,\n",
    "        weights=None\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'train_data': train_data,\n",
    "        'valid_data': valid_data,\n",
    "        'scaler': scaler,\n",
    "        'scaler_num': scaler_num,\n",
    "        'config': config,\n",
    "        'solvent_dim': solvent_dim,\n",
    "        'smiles_extra_dim': smiles_extra_dim,\n",
    "        'fp_size': fp_size,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úÖ Data loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9428a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Training Functions\n",
    "# ============================================================================\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device, use_lds=True):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        graphs, fps, labels, masks, weights = batch\n",
    "        \n",
    "        graphs = graphs.to(device)\n",
    "        fps = fps.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        node_feats = graphs.ndata['hv']\n",
    "        edge_feats = graphs.edata.get('he', None)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(graphs, node_feats, edge_feats, fps)\n",
    "        \n",
    "        if use_lds and weights is not None:\n",
    "            weights = weights.to(device)\n",
    "            loss = (criterion(predictions, labels) * weights.unsqueeze(1)).mean()\n",
    "        else:\n",
    "            loss = criterion(predictions, labels).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate model on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            graphs, fps, labels, masks, _ = batch\n",
    "            \n",
    "            graphs = graphs.to(device)\n",
    "            fps = fps.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            node_feats = graphs.ndata['hv']\n",
    "            edge_feats = graphs.edata.get('he', None)\n",
    "            \n",
    "            predictions = model(graphs, node_feats, edge_feats, fps)\n",
    "            loss = criterion(predictions, labels).mean()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            all_preds.append(predictions.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    return total_loss / num_batches, all_preds, all_labels\n",
    "\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efa11c",
   "metadata": {},
   "source": [
    "## 8. Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8e1f967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Main training function defined (with early checkpoint check)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Main Training Function with Checkpoint Resumption\n",
    "# ============================================================================\n",
    "\n",
    "def find_checkpoint(checkpoint_dir, target):\n",
    "    \"\"\"Check if a checkpoint exists for the given target.\"\"\"\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{target}.pth')\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        return checkpoint_path\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_checkpoint_status(checkpoint_path, epochs, patience):\n",
    "    \"\"\"Check if training is already complete without loading full checkpoint into model.\"\"\"\n",
    "    if not checkpoint_path:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        ckpt = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "        epoch = ckpt.get('epoch', 0)\n",
    "        epochs_without_improvement = ckpt.get('epochs_without_improvement', 0)\n",
    "        best_val_loss = ckpt.get('best_val_loss', float('inf'))\n",
    "        history = ckpt.get('history', {'train_loss': [], 'val_loss': []})\n",
    "        \n",
    "        is_complete = epochs_without_improvement >= patience or epoch >= epochs\n",
    "        \n",
    "        return {\n",
    "            'epoch': epoch,\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'epochs_without_improvement': epochs_without_improvement,\n",
    "            'history': history,\n",
    "            'is_complete': is_complete,\n",
    "            'scaler_mean': ckpt.get('scaler_mean'),\n",
    "            'scaler_scale': ckpt.get('scaler_scale'),\n",
    "            'best_model_state': ckpt.get('model_state_dict'),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Failed to read checkpoint: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_path, model, optimizer, device):\n",
    "    \"\"\"Load checkpoint and return training state.\"\"\"\n",
    "    print(f\"   üìÇ Loading checkpoint from: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    # Move optimizer states to device\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.to(device)\n",
    "    \n",
    "    return {\n",
    "        'epoch': checkpoint['epoch'],\n",
    "        'best_val_loss': checkpoint['best_val_loss'],\n",
    "        'history': checkpoint.get('history', {'train_loss': [], 'val_loss': []}),\n",
    "        'epochs_without_improvement': checkpoint.get('epochs_without_improvement', 0),\n",
    "        'best_model_state': checkpoint['model_state_dict'],\n",
    "    }\n",
    "\n",
    "\n",
    "def save_checkpoint(checkpoint_dir, target, epoch, model, optimizer, best_val_loss, \n",
    "                    best_model_state, history, epochs_without_improvement, scaler, config):\n",
    "    \"\"\"Save comprehensive checkpoint with all training state.\"\"\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{target}.pth')\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': best_model_state,\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'history': history,\n",
    "        'epochs_without_improvement': epochs_without_improvement,\n",
    "        'scaler_mean': scaler.mean_.tolist(),\n",
    "        'scaler_scale': scaler.scale_.tolist(),\n",
    "        'config': config,\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    return checkpoint_path\n",
    "\n",
    "\n",
    "def train_model(target, data_dir='./data', output_dir='./models', \n",
    "                checkpoint_dir='./checkpoints', epochs=200, patience=20, device='cuda',\n",
    "                resume=True):\n",
    "    \"\"\"Train a single property prediction model with checkpoint saving and resumption.\n",
    "    \n",
    "    Uses MODEL_CONFIGS to determine model architecture:\n",
    "    - abs/em: GraphFingerprintsModel (CNN attention + solvent extractor)\n",
    "    - plqy/k: GraphFingerprintsModelFC (simple FC for all fingerprints)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üöÄ Training model for: {target.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get model config\n",
    "    config = MODEL_CONFIGS[target]\n",
    "    model_class_name = config['model_class']\n",
    "    print(f\"   Config: {config}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # EARLY CHECK: See if training is already complete BEFORE loading data\n",
    "    # =========================================================================\n",
    "    checkpoint_path = find_checkpoint(checkpoint_dir, target) if resume else None\n",
    "    \n",
    "    if checkpoint_path:\n",
    "        ckpt_status = check_checkpoint_status(checkpoint_path, epochs, patience)\n",
    "        \n",
    "        if ckpt_status and ckpt_status['is_complete']:\n",
    "            # Training already done - return cached results without loading data\n",
    "            print(f\"   üìÇ Found completed checkpoint\")\n",
    "            print(f\"   ‚úÖ Already trained: epoch {ckpt_status['epoch']}, \" + \n",
    "                  f\"val_loss={ckpt_status['best_val_loss']:.4f}\")\n",
    "            \n",
    "            if ckpt_status['epochs_without_improvement'] >= patience:\n",
    "                print(f\"   ‚èπÔ∏è Early stopped at epoch {ckpt_status['epoch']} \" +\n",
    "                      f\"(no improvement for {patience} epochs)\")\n",
    "            else:\n",
    "                print(f\"   ‚èπÔ∏è Completed {epochs} epochs\")\n",
    "            \n",
    "            # Save model to output_dir from checkpoint (so predictions work)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            model_path = os.path.join(output_dir, f'Model_{target}.pth')\n",
    "            if ckpt_status['best_model_state'] is not None:\n",
    "                torch.save(ckpt_status['best_model_state'], model_path)\n",
    "                print(f\"   üíæ Model saved to: {model_path}\")\n",
    "            \n",
    "            # Return results using cached scaler params (no data loading needed!)\n",
    "            return {\n",
    "                'target': target,\n",
    "                'best_val_loss': ckpt_status['best_val_loss'],\n",
    "                'mae': float('nan'),  # Would need validation data to compute\n",
    "                'rmse': float('nan'),\n",
    "                'r2': float('nan'),\n",
    "                'epochs_trained': ckpt_status['epoch'],\n",
    "                'training_time': 0,\n",
    "                'history': ckpt_status['history'],\n",
    "                'resumed': True,\n",
    "                'already_complete': True,\n",
    "            }\n",
    "        elif ckpt_status:\n",
    "            print(f\"   üìÇ Found in-progress checkpoint at epoch {ckpt_status['epoch']}\")\n",
    "            print(f\"   üîÑ Will resume training...\")\n",
    "    else:\n",
    "        print(f\"   üìù No checkpoint found, will train from scratch\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Only load data if we actually need to train\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Get feature dimensions\n",
    "    sample_graph = smiles_to_graph('CCO')\n",
    "    n_feats = sample_graph.ndata['hv'].shape[1]\n",
    "    e_feats = sample_graph.edata['he'].shape[1]\n",
    "    print(f\"   Node features: {n_feats}, Edge features: {e_feats}\")\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"\\nüìÇ Loading data for {target}...\")\n",
    "    data = load_and_process_data(target, data_dir, config)\n",
    "    \n",
    "    # Create data loaders with GPU optimization\n",
    "    train_loader = DataLoader(\n",
    "        data['train_data'],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        data['valid_data'],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Initialize model based on model_class\n",
    "    if model_class_name == 'GraphFingerprintsModel':\n",
    "        # abs/em: CNN attention + solvent extractor\n",
    "        model = GraphFingerprintsModel(\n",
    "            node_feat_size=n_feats,\n",
    "            edge_feat_size=e_feats,\n",
    "            solvent_dim=data['solvent_dim'],\n",
    "            smiles_extra_dim=data['smiles_extra_dim'],\n",
    "            graph_feat_size=GRAPH_FEAT_SIZE,\n",
    "            num_layers=config['num_layers'],\n",
    "            num_timesteps=config['num_timesteps'],\n",
    "            n_tasks=1,\n",
    "            dropout=config['dropout']\n",
    "        ).to(device)\n",
    "    else:\n",
    "        # plqy/k: Simple FC for all fingerprints\n",
    "        model = GraphFingerprintsModelFC(\n",
    "            node_feat_size=n_feats,\n",
    "            edge_feat_size=e_feats,\n",
    "            fp_size=data['fp_size'],\n",
    "            graph_feat_size=GRAPH_FEAT_SIZE,\n",
    "            num_layers=config['num_layers'],\n",
    "            num_timesteps=config['num_timesteps'],\n",
    "            n_tasks=1,\n",
    "            dropout=config['dropout']\n",
    "        ).to(device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"   Model parameters: {total_params:,}\")\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Learning rate scheduler (reduce on plateau)\n",
    "    scheduler = None\n",
    "    if USE_LR_SCHEDULER:\n",
    "        from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min', \n",
    "            factor=LR_SCHEDULER_FACTOR, \n",
    "            patience=LR_SCHEDULER_PATIENCE,\n",
    "            min_lr=LR_SCHEDULER_MIN\n",
    "        )\n",
    "    \n",
    "    # Initialize training state\n",
    "    start_epoch = 1\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_without_improvement = 0\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    # Load checkpoint if resuming\n",
    "    if checkpoint_path:\n",
    "        try:\n",
    "            ckpt = load_checkpoint(checkpoint_path, model, optimizer, device)\n",
    "            start_epoch = ckpt['epoch'] + 1\n",
    "            best_val_loss = ckpt['best_val_loss']\n",
    "            best_model_state = ckpt['best_model_state']\n",
    "            history = ckpt['history']\n",
    "            epochs_without_improvement = ckpt['epochs_without_improvement']\n",
    "            \n",
    "            print(f\"   ‚úÖ Resuming from epoch {start_epoch}\")\n",
    "            print(f\"   Previous best val loss: {best_val_loss:.4f}\")\n",
    "            print(f\"   Epochs without improvement: {epochs_without_improvement}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Failed to load checkpoint: {e}\")\n",
    "            print(f\"   Starting fresh training...\")\n",
    "            start_epoch = 1\n",
    "            best_val_loss = float('inf')\n",
    "            best_model_state = None\n",
    "            epochs_without_improvement = 0\n",
    "            history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    use_lds = config['alpha'] > 0\n",
    "    \n",
    "    remaining_epochs = epochs - start_epoch + 1\n",
    "    print(f\"\\nüìà Training epochs {start_epoch} to {epochs} ({remaining_epochs} remaining)\")\n",
    "    print(f\"   Patience: {patience}, Using LDS: {use_lds}\")\n",
    "    \n",
    "    # Monitor GPU memory\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    pbar = tqdm(range(start_epoch, epochs + 1), desc=f\"{target.upper()}\", unit=\"epoch\", \n",
    "                dynamic_ncols=True, leave=True)\n",
    "    final_epoch = start_epoch - 1\n",
    "    last_lr = LEARNING_RATE\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device, use_lds)\n",
    "        val_loss, val_preds, val_labels = validate(model, valid_loader, criterion, device)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        # Step the learning rate scheduler\n",
    "        if scheduler is not None:\n",
    "            old_lr = optimizer.param_groups[0]['lr']\n",
    "            scheduler.step(val_loss)\n",
    "            new_lr = optimizer.param_groups[0]['lr']\n",
    "            if new_lr < old_lr:\n",
    "                print(f\"   üìâ LR reduced: {old_lr:.2e} ‚Üí {new_lr:.2e}\")\n",
    "                last_lr = new_lr\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            epochs_without_improvement = 0\n",
    "            improved = True\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            improved = False\n",
    "        \n",
    "        # Save checkpoint (every epoch for robustness against disconnection)\n",
    "        save_checkpoint(\n",
    "            checkpoint_dir, target, epoch, model, optimizer,\n",
    "            best_val_loss, best_model_state, history, \n",
    "            epochs_without_improvement, data['scaler'], config\n",
    "        )\n",
    "        \n",
    "        # Update progress bar\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix({\n",
    "            'train': f'{train_loss:.4f}',\n",
    "            'val': f'{val_loss:.4f}',\n",
    "            'best': f'{best_val_loss:.4f}',\n",
    "            'no_improv': epochs_without_improvement,\n",
    "            'lr': f'{current_lr:.1e}',\n",
    "        })\n",
    "        \n",
    "        # Print periodic updates (every 10 epochs or on improvement) as fallback\n",
    "        if epoch % 10 == 0 or improved or epoch == start_epoch:\n",
    "            star = \" ‚òÖ new best!\" if improved else \"\"\n",
    "            print(f\"   Epoch {epoch:3d}/{epochs}: train={train_loss:.4f}, val={val_loss:.4f}, best={best_val_loss:.4f}{star}\")\n",
    "        \n",
    "        final_epoch = epoch\n",
    "        \n",
    "        # Early stopping\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"\\n‚èπÔ∏è Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    _, val_preds, val_labels = validate(model, valid_loader, criterion, device)\n",
    "    \n",
    "    # Inverse transform predictions\n",
    "    val_preds_orig = data['scaler'].inverse_transform(val_preds)\n",
    "    val_labels_orig = data['scaler'].inverse_transform(val_labels)\n",
    "    \n",
    "    mae = mean_absolute_error(val_labels_orig, val_preds_orig)\n",
    "    rmse = np.sqrt(mean_squared_error(val_labels_orig, val_preds_orig))\n",
    "    r2 = r2_score(val_labels_orig, val_preds_orig)\n",
    "    \n",
    "    print(f\"\\nüìä Final Metrics (original scale):\")\n",
    "    print(f\"   MAE:  {mae:.4f}\")\n",
    "    print(f\"   RMSE: {rmse:.4f}\")\n",
    "    print(f\"   R¬≤:   {r2:.4f}\")\n",
    "    \n",
    "    # Report GPU memory usage\n",
    "    if device == 'cuda':\n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1e9\n",
    "        print(f\"   Peak GPU memory: {peak_memory:.2f} GB\")\n",
    "    \n",
    "    # Save final model\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model_path = os.path.join(output_dir, f'Model_{target}.pth')\n",
    "    torch.save(best_model_state, model_path)\n",
    "    print(f\"\\nüíæ Model saved to: {model_path}\")\n",
    "    \n",
    "    # Calculate training time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, remainder = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    time_str = f\"{int(hours)}h {int(minutes)}m {int(seconds)}s\"\n",
    "    print(f\"‚è±Ô∏è Training time: {time_str}\")\n",
    "    \n",
    "    return {\n",
    "        'target': target,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'epochs_trained': final_epoch,\n",
    "        'training_time': elapsed_time,\n",
    "        'history': history,\n",
    "        'resumed': checkpoint_path is not None,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úÖ Main training function defined (with early checkpoint check)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1bd423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Models to train: ['abs', 'em', 'plqy', 'k']\n",
      "üìÅ Data directory: ./fluor_tools/Fluor-RLAT/data\n",
      "üìÅ Output directory: ./models\n",
      "üíæ Checkpoints: /content/drive/MyDrive/fluor_checkpoints\n",
      "‚öôÔ∏è  Epochs: 200, Patience: 30\n",
      "üîÑ Resume from checkpoint: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Training Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# Paths - using cloned repository data\n",
    "DATA_DIR = './fluor_tools/Fluor-RLAT/data'\n",
    "OUTPUT_DIR = './models'\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/fluor_checkpoints'  # Save checkpoints to Drive\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 200\n",
    "PATIENCE = 30\n",
    "\n",
    "# Resume from checkpoints if they exist\n",
    "RESUME_FROM_CHECKPOINT = True  # Set to False to start fresh\n",
    "\n",
    "# Select which models to train\n",
    "# Options: 'abs', 'em', 'plqy', 'k'\n",
    "TARGETS = ['abs', 'em', 'plqy', 'k']  # Train all models\n",
    "# TARGETS = ['abs']  # Train only absorption model\n",
    "\n",
    "print(f\"üéØ Models to train: {TARGETS}\")\n",
    "print(f\"üìÅ Data directory: {DATA_DIR}\")\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"üíæ Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"‚öôÔ∏è  Epochs: {EPOCHS}, Patience: {PATIENCE}\")\n",
    "print(f\"üîÑ Resume from checkpoint: {RESUME_FROM_CHECKPOINT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e2244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Check Existing Checkpoints\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"üîç Checking for existing checkpoints in: {CHECKPOINT_DIR}\\n\")\n",
    "\n",
    "if os.path.exists(CHECKPOINT_DIR):\n",
    "    found_checkpoints = []\n",
    "    for target in TARGETS:\n",
    "        ckpt_path = os.path.join(CHECKPOINT_DIR, f'checkpoint_{target}.pth')\n",
    "        if os.path.exists(ckpt_path):\n",
    "            try:\n",
    "                ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "                epoch = ckpt.get('epoch', '?')\n",
    "                val_loss = ckpt.get('best_val_loss', '?')\n",
    "                timestamp = ckpt.get('timestamp', 'unknown')\n",
    "                epochs_no_improv = ckpt.get('epochs_without_improvement', 0)\n",
    "                \n",
    "                status = \"‚úÖ Complete\" if epochs_no_improv >= PATIENCE or epoch >= EPOCHS else \"üîÑ In progress\"\n",
    "                \n",
    "                found_checkpoints.append({\n",
    "                    'target': target,\n",
    "                    'epoch': epoch,\n",
    "                    'val_loss': val_loss,\n",
    "                    'timestamp': timestamp,\n",
    "                    'status': status,\n",
    "                    'epochs_no_improv': epochs_no_improv,\n",
    "                })\n",
    "                print(f\"  üì¶ {target.upper()}: Epoch {epoch}, Val Loss: {val_loss:.4f}, {status}\")\n",
    "                print(f\"      Last saved: {timestamp}, No improvement: {epochs_no_improv}/{PATIENCE}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è  {target.upper()}: Checkpoint exists but failed to read: {e}\")\n",
    "        else:\n",
    "            print(f\"  ‚¨ú {target.upper()}: No checkpoint found\")\n",
    "    \n",
    "    if found_checkpoints and RESUME_FROM_CHECKPOINT:\n",
    "        print(f\"\\n‚úÖ Will resume training from existing checkpoints\")\n",
    "    elif found_checkpoints and not RESUME_FROM_CHECKPOINT:\n",
    "        print(f\"\\n‚ö†Ô∏è  Checkpoints exist but RESUME_FROM_CHECKPOINT=False\")\n",
    "        print(f\"   Training will start fresh (existing checkpoints ignored)\")\n",
    "else:\n",
    "    print(f\"  üìÅ Checkpoint directory does not exist yet\")\n",
    "    print(f\"  üìù Will start fresh training for all models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff5487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üöÄ START TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "total_start = time.time()\n",
    "results = []\n",
    "\n",
    "for target in TARGETS:\n",
    "    result = train_model(\n",
    "        target=target,\n",
    "        data_dir=DATA_DIR,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        checkpoint_dir=CHECKPOINT_DIR,\n",
    "        epochs=EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        device=device,\n",
    "        resume=RESUME_FROM_CHECKPOINT  # Use checkpoint if available\n",
    "    )\n",
    "    results.append(result)\n",
    "    \n",
    "    # Clear GPU cache between models\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "total_elapsed = time.time() - total_start\n",
    "\n",
    "# ============================================================================\n",
    "# Summary\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìã TRAINING SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for r in results:\n",
    "    t = r['training_time']\n",
    "    h, rem = divmod(t, 3600)\n",
    "    m, s = divmod(rem, 60)\n",
    "    time_str = f\"{int(h)}h {int(m)}m {int(s)}s\" if t > 0 else \"0s (loaded from checkpoint)\"\n",
    "    \n",
    "    resumed = \" (resumed)\" if r.get('resumed', False) else \"\"\n",
    "    complete = \" [already complete]\" if r.get('already_complete', False) else \"\"\n",
    "    \n",
    "    print(f\"\\n{r['target'].upper()}{resumed}{complete}:\")\n",
    "    print(f\"   Epochs: {r['epochs_trained']}, Time: {time_str}\")\n",
    "    print(f\"   MAE: {r['mae']:.4f}, RMSE: {r['rmse']:.4f}, R¬≤: {r['r2']:.4f}\")\n",
    "\n",
    "total_h, total_rem = divmod(total_elapsed, 3600)\n",
    "total_m, total_s = divmod(total_rem, 60)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚è±Ô∏è Total training time: {int(total_h)}h {int(total_m)}m {int(total_s)}s\")\n",
    "print(f\"‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b09a1",
   "metadata": {},
   "source": [
    "## 9. Download Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b84758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List trained models\n",
    "print(\"Trained models:\")\n",
    "for f in os.listdir(OUTPUT_DIR):\n",
    "    if f.endswith('.pth'):\n",
    "        size = os.path.getsize(os.path.join(OUTPUT_DIR, f)) / 1e6\n",
    "        print(f\"  üì¶ {f} ({size:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Copy to Google Drive\n",
    "DRIVE_OUTPUT = \"/content/drive/MyDrive/fluor_models\"\n",
    "os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n",
    "\n",
    "for f in os.listdir(OUTPUT_DIR):\n",
    "    if f.endswith('.pth'):\n",
    "        src = os.path.join(OUTPUT_DIR, f)\n",
    "        dst = os.path.join(DRIVE_OUTPUT, f)\n",
    "        !cp \"{src}\" \"{dst}\"\n",
    "\n",
    "print(f\"‚úÖ Models copied to: {DRIVE_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb540a",
   "metadata": {},
   "source": [
    "## 10. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8702ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, r in enumerate(results):\n",
    "    if idx >= 4:\n",
    "        break\n",
    "    ax = axes[idx]\n",
    "    ax.plot(r['history']['train_loss'], label='Train Loss', alpha=0.8)\n",
    "    ax.plot(r['history']['val_loss'], label='Val Loss', alpha=0.8)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title(f\"{r['target'].upper()} - MAE: {r['mae']:.2f}, R¬≤: {r['r2']:.3f}\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(len(results), 4):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to Google Drive\n",
    "plot_path = os.path.join(DRIVE_OUTPUT, 'training_history.png')\n",
    "plt.savefig(plot_path, dpi=150)\n",
    "plt.show()\n",
    "print(f\"üìä Plot saved to: {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1dabf9",
   "metadata": {},
   "source": [
    "## 11. Make Predictions\n",
    "\n",
    "Use the trained models to predict properties for a new molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Prediction Input\n",
    "# ============================================================================\n",
    "\n",
    "molecule = \"C2=C1C7=C(C(=[N+]1[B-]([N]3C2=C5C(=C3C4=CC=CC=C4)C=CC=C5)(F)F)C6=CC=CC=C6)C=CC=C7\"\n",
    "solvent = \"CC1=CC=CC=C1\"\n",
    "\n",
    "print(f\"üß™ Molecule: {molecule}\")\n",
    "print(f\"üß´ Solvent:  {solvent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Run Prediction\n",
    "# ============================================================================\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def predict_properties(molecule_smiles, solvent_smiles, model_dir='./models', \n",
    "                       checkpoint_dir='/content/drive/MyDrive/fluor_checkpoints', device='cuda'):\n",
    "    \"\"\"Predict all properties for a single molecule with proper preprocessing and inverse scaling.\n",
    "    \n",
    "    This function mimics the preprocessing from 02_property_prediction.py.\n",
    "    Uses MODEL_CONFIGS which matches ORIGINAL_MODEL_CONFIGS for consistency.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate molecular graph\n",
    "    graph = smiles_to_graph(molecule_smiles)\n",
    "    if graph is None:\n",
    "        raise ValueError(f\"Could not parse molecule SMILES: {molecule_smiles}\")\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(molecule_smiles)\n",
    "    sol = Chem.MolFromSmiles(solvent_smiles)\n",
    "    if mol is None or sol is None:\n",
    "        raise ValueError(\"Invalid SMILES\")\n",
    "    \n",
    "    # Generate Morgan fingerprints (1024-bit, radius 2)\n",
    "    mol_fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)\n",
    "    sol_fp = AllChem.GetMorganFingerprintAsBitVect(sol, radius=2, nBits=1024)\n",
    "    mol_fp_arr = np.array(mol_fp, dtype=np.float32)\n",
    "    sol_fp_arr = np.array(sol_fp, dtype=np.float32)\n",
    "    \n",
    "    # Compute molecular descriptors\n",
    "    mw = Descriptors.MolWt(mol)\n",
    "    logp = Descriptors.MolLogP(mol)\n",
    "    tpsa = Descriptors.TPSA(mol)\n",
    "    double_bonds = sum(1 for bond in mol.GetBonds() \n",
    "                       if bond.GetBondType() == Chem.BondType.DOUBLE or bond.GetIsAromatic())\n",
    "    ring_count = mol.GetRingInfo().NumRings()\n",
    "    \n",
    "    # Get solvent_num from mapping (simplified)\n",
    "    solvent_mapping = {\n",
    "        'CC1=CC=CC=C1': 6, 'Cc1ccccc1': 6,  # toluene\n",
    "        'CCO': 2, 'CO': 1, 'c1ccccc1': 5,\n",
    "    }\n",
    "    solvent_num = solvent_mapping.get(solvent_smiles, 0)\n",
    "    \n",
    "    # Detect scaffold (simplified - check for BODIPY)\n",
    "    bodipy_smarts = '[#5](-F)(-F)(-[#7])(-[#7])'\n",
    "    tag = 0\n",
    "    bodipy_pattern = Chem.MolFromSmarts(bodipy_smarts)\n",
    "    if bodipy_pattern and mol.HasSubstructMatch(bodipy_pattern):\n",
    "        tag = 5  # BODIPY\n",
    "    \n",
    "    # Create 136 scaffold flags\n",
    "    scaffold_flags = np.zeros(136, dtype=np.float32)\n",
    "    if tag == 5:  # BODIPY\n",
    "        scaffold_flags[3] = 1  # fragment_4\n",
    "    \n",
    "    unimol_plus = 3.49  # placeholder\n",
    "    \n",
    "    # Numeric features: [solvent_num, tag, MW, LogP, TPSA, double_bonds, ring_count, unimol_plus]\n",
    "    numeric_feats = np.array([solvent_num, tag, mw, logp, tpsa, double_bonds, ring_count, unimol_plus], dtype=np.float32)\n",
    "    \n",
    "    predictions = {}\n",
    "    n_feats = graph.ndata['hv'].shape[1]\n",
    "    e_feats = graph.edata['he'].shape[1]\n",
    "    \n",
    "    for target in ['abs', 'em', 'plqy', 'k']:\n",
    "        model_path = os.path.join(model_dir, f'Model_{target}.pth')\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"   ‚ö†Ô∏è Model not found: {model_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Load scaler parameters from checkpoint\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{target}.pth')\n",
    "        scaler_mean = None\n",
    "        scaler_scale = None\n",
    "        num_scaler_min = None\n",
    "        num_scaler_scale = None\n",
    "        \n",
    "        if os.path.exists(checkpoint_path):\n",
    "            ckpt = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "            scaler_mean = ckpt.get('scaler_mean', [0])[0]\n",
    "            scaler_scale = ckpt.get('scaler_scale', [1])[0]\n",
    "            # Load numeric scaler if saved\n",
    "            num_scaler_min = ckpt.get('num_scaler_min', None)\n",
    "            num_scaler_scale = ckpt.get('num_scaler_scale', None)\n",
    "        \n",
    "        # Apply numeric scaling if available, otherwise use raw values\n",
    "        if num_scaler_min is not None and num_scaler_scale is not None:\n",
    "            numeric_scaled = (numeric_feats - np.array(num_scaler_min)) / np.array(num_scaler_scale)\n",
    "        else:\n",
    "            # Fallback: use MinMaxScaler from training data\n",
    "            train_path = os.path.join(DATA_DIR, f'train_{target}.csv')\n",
    "            if os.path.exists(train_path):\n",
    "                train_df = pd.read_csv(train_path)\n",
    "                train_numeric = train_df.iloc[:, 8:16].values\n",
    "                num_scaler = MinMaxScaler()\n",
    "                num_scaler.fit(train_numeric)\n",
    "                numeric_scaled = num_scaler.transform(numeric_feats.reshape(1, -1)).flatten()\n",
    "            else:\n",
    "                numeric_scaled = numeric_feats  # no scaling if no data\n",
    "        \n",
    "        # Combine extra features\n",
    "        extra_feats = np.concatenate([numeric_scaled, scaffold_flags]).astype(np.float32)\n",
    "        \n",
    "        config = MODEL_CONFIGS[target]\n",
    "        model_class = config['model_class']\n",
    "        \n",
    "        # Build fingerprint tensor: [solvent_fp(1024), smiles_fp(1024), extra(144)] = 2192\n",
    "        fp = np.concatenate([sol_fp_arr, mol_fp_arr, extra_feats])\n",
    "        \n",
    "        if model_class == 'GraphFingerprintsModel':\n",
    "            # abs/em use CNN attention architecture\n",
    "            solvent_dim = 1024\n",
    "            smiles_extra_dim = len(fp) - solvent_dim  # 1024 + 144 = 1168\n",
    "            \n",
    "            model = GraphFingerprintsModel(\n",
    "                node_feat_size=n_feats,\n",
    "                edge_feat_size=e_feats,\n",
    "                solvent_dim=solvent_dim,\n",
    "                smiles_extra_dim=smiles_extra_dim,\n",
    "                graph_feat_size=GRAPH_FEAT_SIZE,\n",
    "                num_layers=config['num_layers'],\n",
    "                num_timesteps=config['num_timesteps'],\n",
    "                n_tasks=1,\n",
    "                dropout=config['dropout']\n",
    "            )\n",
    "        else:\n",
    "            # plqy/k use simple FC architecture\n",
    "            model = GraphFingerprintsModelFC(\n",
    "                node_feat_size=n_feats,\n",
    "                edge_feat_size=e_feats,\n",
    "                fp_size=len(fp),  # 2192\n",
    "                graph_feat_size=GRAPH_FEAT_SIZE,\n",
    "                num_layers=config['num_layers'],\n",
    "                num_timesteps=config['num_timesteps'],\n",
    "                n_tasks=1,\n",
    "                dropout=config['dropout']\n",
    "            )\n",
    "        \n",
    "        # Load weights\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # Prepare inputs\n",
    "        graph_batch = dgl.batch([graph]).to(device)\n",
    "        node_feats = graph_batch.ndata['hv']\n",
    "        edge_feats = graph_batch.edata['he']\n",
    "        fp_tensor = torch.tensor(fp, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            pred = model(graph_batch, node_feats, edge_feats, fp_tensor)\n",
    "            pred_scaled = pred.item()\n",
    "        \n",
    "        # Inverse transform: original = scaled * scale + mean\n",
    "        if scaler_mean is not None and scaler_scale is not None:\n",
    "            pred_value = pred_scaled * scaler_scale + scaler_mean\n",
    "        else:\n",
    "            pred_value = pred_scaled\n",
    "        \n",
    "        predictions[target] = pred_value\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Run prediction\n",
    "print(\"\\nüîÆ Running predictions...\")\n",
    "preds = predict_properties(molecule, solvent, model_dir=OUTPUT_DIR, \n",
    "                           checkpoint_dir=CHECKPOINT_DIR, device=device)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä PREDICTION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"   Absorption (abs):    {preds.get('abs', 'N/A'):.1f} nm\")\n",
    "print(f\"   Emission (em):       {preds.get('em', 'N/A'):.1f} nm\")\n",
    "print(f\"   Quantum Yield (plqy): {preds.get('plqy', 'N/A'):.3f}\")\n",
    "print(f\"   Log Œµ (k):           {preds.get('k', 'N/A'):.2f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Compare Old (Pretrained) vs New (Just Trained) Models\n",
    "# ============================================================================\n",
    "# \n",
    "# IMPORTANT: The original models require the FULL preprocessing pipeline:\n",
    "# 1. Solvent mapping (solvent SMILES -> solvent_num via 00_solvent_mapping.csv)\n",
    "# 2. Scaffold detection (match against 136 substructures)\n",
    "# 3. MinMaxScaler normalization on 8 numeric features (fit on training data)\n",
    "# 4. Scaler inverse transform on predictions\n",
    "#\n",
    "# For a quick comparison, we'll load the preprocessed input.csv that was \n",
    "# generated by the original pipeline.\n",
    "\n",
    "OLD_MODEL_DIR = './fluor_tools/Fluor-RLAT'  # Original pretrained models from repo\n",
    "NEW_MODEL_DIR = './models'  # Newly trained models\n",
    "ORIGINAL_DATA_DIR = './fluor_tools/Fluor-RLAT/data'  # Training data for scalers\n",
    "\n",
    "def predict_with_original_model_proper(molecule_smiles, solvent_smiles, model_dir, data_dir, device='cuda'):\n",
    "    \"\"\"Predict using original pretrained models with proper preprocessing.\n",
    "    \n",
    "    This function mimics the original 02_property_prediction.py pipeline.\n",
    "    Uses ORIGINAL_MODEL_CONFIGS which matches the pretrained model architectures.\n",
    "    \"\"\"\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import AllChem, Descriptors\n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "    \n",
    "    # Step 1: Create molecular graph\n",
    "    graph = smiles_to_graph(molecule_smiles)\n",
    "    if graph is None:\n",
    "        raise ValueError(f\"Could not parse molecule SMILES: {molecule_smiles}\")\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(molecule_smiles)\n",
    "    sol = Chem.MolFromSmiles(solvent_smiles)\n",
    "    if mol is None or sol is None:\n",
    "        raise ValueError(\"Invalid SMILES\")\n",
    "    \n",
    "    # Step 2: Generate Morgan fingerprints (1024-bit, radius 2)\n",
    "    mol_fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)\n",
    "    sol_fp = AllChem.GetMorganFingerprintAsBitVect(sol, radius=2, nBits=1024)\n",
    "    mol_fp_arr = np.array(mol_fp, dtype=np.float32)\n",
    "    sol_fp_arr = np.array(sol_fp, dtype=np.float32)\n",
    "    \n",
    "    # Step 3: Compute molecular descriptors\n",
    "    mw = Descriptors.MolWt(mol)\n",
    "    logp = Descriptors.MolLogP(mol)\n",
    "    tpsa = Descriptors.TPSA(mol)\n",
    "    double_bonds = sum(1 for bond in mol.GetBonds() \n",
    "                       if bond.GetBondType() == Chem.BondType.DOUBLE or bond.GetIsAromatic())\n",
    "    ring_count = mol.GetRingInfo().NumRings()\n",
    "    \n",
    "    # Step 4: Get solvent_num from mapping (simplified - use 6 for toluene)\n",
    "    solvent_mapping = {\n",
    "        'CC1=CC=CC=C1': 6,  # toluene\n",
    "        'Cc1ccccc1': 6,    # toluene (alternative)\n",
    "        'CCO': 2,          # ethanol\n",
    "        'CO': 1,           # methanol\n",
    "        'c1ccccc1': 5,     # benzene\n",
    "    }\n",
    "    solvent_num = solvent_mapping.get(solvent_smiles, 0)\n",
    "    \n",
    "    # Step 5: Detect scaffold (simplified - check for BODIPY)\n",
    "    bodipy_smarts = '[#5](-F)(-F)(-[#7])(-[#7])'\n",
    "    tag = 0\n",
    "    tag_name = 'Unknown'\n",
    "    bodipy_pattern = Chem.MolFromSmarts(bodipy_smarts)\n",
    "    if bodipy_pattern and mol.HasSubstructMatch(bodipy_pattern):\n",
    "        tag = 5  # BODIPY tag\n",
    "        tag_name = 'BODIPY'\n",
    "    \n",
    "    # Step 6: Create 136 scaffold flags (simplified - just set fragment_4 for BODIPY)\n",
    "    scaffold_flags = np.zeros(136, dtype=np.float32)\n",
    "    if tag == 5:  # BODIPY\n",
    "        scaffold_flags[3] = 1  # fragment_4 (0-indexed as 3)\n",
    "    \n",
    "    # Step 7: Get unimol_plus placeholder\n",
    "    unimol_plus = 3.49  # placeholder\n",
    "    \n",
    "    # Numeric features in correct order: [solvent_num, tag, MW, LogP, TPSA, double_bonds, ring_count, unimol_plus]\n",
    "    numeric_feats = np.array([solvent_num, tag, mw, logp, tpsa, double_bonds, ring_count, unimol_plus], dtype=np.float32)\n",
    "    \n",
    "    predictions = {}\n",
    "    raw_predictions = {}\n",
    "    n_feats = graph.ndata['hv'].shape[1]\n",
    "    e_feats = graph.edata['he'].shape[1]\n",
    "    \n",
    "    for target in ['abs', 'em', 'plqy', 'k']:\n",
    "        model_path = os.path.join(model_dir, f'Model_{target}.pth')\n",
    "        if not os.path.exists(model_path):\n",
    "            continue\n",
    "        \n",
    "        # Load training data to fit scalers (same as original pipeline)\n",
    "        train_path = os.path.join(data_dir, f'train_{target}.csv')\n",
    "        if not os.path.exists(train_path):\n",
    "            print(f\"   ‚ö†Ô∏è Training data not found: {train_path}\")\n",
    "            continue\n",
    "            \n",
    "        train_df = pd.read_csv(train_path)\n",
    "        \n",
    "        # Fit label scaler\n",
    "        label_scaler = StandardScaler()\n",
    "        label_scaler.fit(train_df[[target]].values)\n",
    "        \n",
    "        # Fit numeric scaler on columns 8:16 of training data\n",
    "        train_numeric = train_df.iloc[:, 8:16].values\n",
    "        num_scaler = MinMaxScaler()\n",
    "        num_scaler.fit(train_numeric)\n",
    "        \n",
    "        # Apply numeric scaler to our features\n",
    "        numeric_scaled = num_scaler.transform(numeric_feats.reshape(1, -1)).flatten()\n",
    "        \n",
    "        # Combine extra features: scaled_numeric (8) + scaffold_flags (136) = 144\n",
    "        extra_feats = np.concatenate([numeric_scaled, scaffold_flags]).astype(np.float32)\n",
    "        \n",
    "        config = ORIGINAL_MODEL_CONFIGS[target]\n",
    "        model_class = config['model_class']\n",
    "        \n",
    "        # Build fingerprint tensor: [solvent_fp(1024), smiles_fp(1024), extra(144)] = 2192\n",
    "        fp = np.concatenate([sol_fp_arr, mol_fp_arr, extra_feats])\n",
    "        \n",
    "        if model_class == 'GraphFingerprintsModel':\n",
    "            # abs/em use CNN attention architecture\n",
    "            solvent_dim = 1024\n",
    "            smiles_extra_dim = len(fp) - solvent_dim  # 1024 + 144 = 1168\n",
    "            \n",
    "            model = GraphFingerprintsModel(\n",
    "                node_feat_size=n_feats,\n",
    "                edge_feat_size=e_feats,\n",
    "                solvent_dim=solvent_dim,\n",
    "                smiles_extra_dim=smiles_extra_dim,\n",
    "                graph_feat_size=256,\n",
    "                num_layers=config['num_layers'],\n",
    "                num_timesteps=config['num_timesteps'],\n",
    "                n_tasks=1,\n",
    "                dropout=config['dropout']\n",
    "            )\n",
    "        else:\n",
    "            # plqy/k use simple FC architecture\n",
    "            model = GraphFingerprintsModelFC(\n",
    "                node_feat_size=n_feats,\n",
    "                edge_feat_size=e_feats,\n",
    "                fp_size=len(fp),  # 2192\n",
    "                graph_feat_size=256,\n",
    "                num_layers=config['num_layers'],\n",
    "                num_timesteps=config['num_timesteps'],\n",
    "                n_tasks=1,\n",
    "                dropout=config['dropout']\n",
    "            )\n",
    "        \n",
    "        model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        graph_batch = dgl.batch([graph]).to(device)\n",
    "        node_feats = graph_batch.ndata['hv']\n",
    "        edge_feats = graph_batch.edata['he']\n",
    "        fp_tensor = torch.tensor(fp, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(graph_batch, node_feats, edge_feats, fp_tensor)\n",
    "            raw_pred = pred.item()\n",
    "            raw_predictions[target] = raw_pred\n",
    "            \n",
    "            # Inverse transform using label scaler\n",
    "            pred_value = label_scaler.inverse_transform([[raw_pred]])[0, 0]\n",
    "            predictions[target] = pred_value\n",
    "    \n",
    "    return predictions, raw_predictions\n",
    "\n",
    "\n",
    "print(\"üî¨ Comparing pretrained vs newly trained models\\n\")\n",
    "print(f\"Molecule: {molecule}\")\n",
    "print(f\"Solvent:  {solvent}\\n\")\n",
    "\n",
    "# Check which models exist\n",
    "old_models_exist = all(os.path.exists(os.path.join(OLD_MODEL_DIR, f'Model_{t}.pth')) for t in ['abs', 'em', 'plqy', 'k'])\n",
    "new_models_exist = all(os.path.exists(os.path.join(NEW_MODEL_DIR, f'Model_{t}.pth')) for t in ['abs', 'em', 'plqy', 'k'])\n",
    "\n",
    "print(f\"Old models found: {'‚úÖ' if old_models_exist else '‚ùå'} ({OLD_MODEL_DIR})\")\n",
    "print(f\"New models found: {'‚úÖ' if new_models_exist else '‚ùå'} ({NEW_MODEL_DIR})\")\n",
    "\n",
    "old_preds = {}\n",
    "old_raw = {}\n",
    "new_preds = {}\n",
    "\n",
    "if old_models_exist:\n",
    "    print(\"\\nüîÆ Running predictions with original pretrained models...\")\n",
    "    try:\n",
    "        old_preds, old_raw = predict_with_original_model_proper(\n",
    "            molecule, solvent, \n",
    "            model_dir=OLD_MODEL_DIR, \n",
    "            data_dir=ORIGINAL_DATA_DIR,\n",
    "            device=device\n",
    "        )\n",
    "        print(\"   ‚úÖ Original model predictions complete\")\n",
    "        print(f\"   Raw outputs (normalized): abs={old_raw.get('abs', 'N/A'):.3f}, em={old_raw.get('em', 'N/A'):.3f}, plqy={old_raw.get('plqy', 'N/A'):.3f}, k={old_raw.get('k', 'N/A'):.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if new_models_exist:\n",
    "    print(\"\\nüîÆ Running predictions with newly trained models...\")\n",
    "    try:\n",
    "        new_preds = predict_properties(molecule, solvent, model_dir=NEW_MODEL_DIR, \n",
    "                                       checkpoint_dir=CHECKPOINT_DIR, device=device)\n",
    "        print(\"   ‚úÖ New model predictions complete\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Display comparison\n",
    "if old_preds or new_preds:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä MODEL COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Property':<20} {'Original':<18} {'Retrained':<18} {'Diff':<12}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Expected values from running the original pipeline\n",
    "    expected = {'abs': 639.89, 'em': 660.38, 'plqy': 0.76, 'k': 5.0}\n",
    "    \n",
    "    for prop, unit, fmt in [('abs', 'nm', '.1f'), ('em', 'nm', '.1f'), ('plqy', '', '.3f'), ('k', '', '.2f')]:\n",
    "        old_val = old_preds.get(prop, float('nan'))\n",
    "        new_val = new_preds.get(prop, float('nan'))\n",
    "        exp_val = expected.get(prop, float('nan'))\n",
    "        \n",
    "        old_str = f\"{old_val:{fmt}} {unit}\".strip() if not np.isnan(old_val) else \"N/A\"\n",
    "        new_str = f\"{new_val:{fmt}} {unit}\".strip() if not np.isnan(new_val) else \"N/A\"\n",
    "        \n",
    "        if not np.isnan(old_val) and not np.isnan(new_val):\n",
    "            diff = new_val - old_val\n",
    "            diff_str = f\"{diff:+{fmt}}\"\n",
    "        else:\n",
    "            diff_str = \"-\"\n",
    "        \n",
    "        prop_name = {'abs': 'Absorption', 'em': 'Emission', 'plqy': 'Quantum Yield', 'k': 'Log Œµ'}[prop]\n",
    "        print(f\"   {prop_name:<17} {old_str:<18} {new_str:<18} {diff_str:<12}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Show expected from original pipeline\n",
    "    print(\"\\nüìã Reference values from original pipeline (run.py):\")\n",
    "    print(f\"   Absorption:    {expected['abs']:.2f} nm\")\n",
    "    print(f\"   Emission:      {expected['em']:.2f} nm\")\n",
    "    print(f\"   Quantum Yield: {expected['plqy']:.2f}\")\n",
    "    print(f\"   Log Œµ:         {expected['k']:.1f}\")\n",
    "    \n",
    "    print(\"\\nüìè Expected value ranges:\")\n",
    "    print(\"   Absorption:    ~300-900 nm\")\n",
    "    print(\"   Emission:      ~350-1000 nm\")\n",
    "    print(\"   Quantum Yield: 0.0-1.0\")\n",
    "    print(\"   Log Œµ:         ~3.0-5.5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
