{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd601f7",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Fluor-RLAT Model Training\n",
    "\n",
    "Train property prediction models for fluorescent molecules on Google Colab with GPU acceleration.\n",
    "\n",
    "**Models:**\n",
    "- `abs` - Absorption wavelength (nm)\n",
    "- `em` - Emission wavelength (nm)\n",
    "- `plqy` - Photoluminescence quantum yield (0-1)\n",
    "- `k` - Log molar absorptivity\n",
    "\n",
    "**Architecture:** AttentiveFP GNN + Fingerprint CNN fusion (~2.3M parameters per model)\n",
    "\n",
    "**Expected training time:** ~1-2 hours total on T4 GPU\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5fdf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current environment\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63a9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install DGL and dgllife (Colab has PyTorch pre-installed)\n",
    "# DGL wheel selection based on CUDA version\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "cuda_version = torch.version.cuda\n",
    "print(f\"Detected CUDA version: {cuda_version}\")\n",
    "\n",
    "# Install DGL for the appropriate CUDA version\n",
    "if cuda_version and cuda_version.startswith('12'):\n",
    "    print(\"Installing DGL for CUDA 12.x...\")\n",
    "    !pip install dgl -f https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html -q\n",
    "elif cuda_version and cuda_version.startswith('11'):\n",
    "    print(\"Installing DGL for CUDA 11.x...\")\n",
    "    !pip install dgl -f https://data.dgl.ai/wheels/torch-2.1/cu118/repo.html -q\n",
    "else:\n",
    "    # Fallback - try latest\n",
    "    print(\"Installing DGL (default)...\")\n",
    "    !pip install dgl -f https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html -q\n",
    "\n",
    "# Install dgllife for molecular graph utilities\n",
    "!pip install dgllife -q\n",
    "\n",
    "# Install tqdm for progress bars (usually present but ensure it's available)\n",
    "!pip install tqdm -q\n",
    "\n",
    "print(\"\\nâœ… Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify DGL installation\n",
    "import dgl\n",
    "print(f\"DGL version: {dgl.__version__}\")\n",
    "\n",
    "# Test CUDA with DGL\n",
    "if torch.cuda.is_available():\n",
    "    g = dgl.graph(([0, 1], [1, 2]))\n",
    "    g = g.to('cuda')\n",
    "    print(f\"DGL graph on CUDA: {g.device}\")\n",
    "    print(\"âœ… DGL CUDA support working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21864423",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive and Setup Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c6577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directories\n",
    "import os\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "os.makedirs('./checkpoints', exist_ok=True)\n",
    "\n",
    "print(\"âœ… Directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155c79d",
   "metadata": {},
   "source": [
    "## 3. Clone Repository and Setup Data\n",
    "\n",
    "Clone the fluor_tools repository directly from GitHub to access training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bafa7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "import os\n",
    "\n",
    "REPO_URL = \"https://github.com/markste-in/fluor_tools.git\"\n",
    "REPO_DIR = \"fluor_tools\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(f\"ðŸ“¥ Cloning repository from {REPO_URL}...\")\n",
    "    !git clone {REPO_URL}\n",
    "    print(\"âœ… Repository cloned!\")\n",
    "else:\n",
    "    print(f\"âœ… Repository already exists at {REPO_DIR}\")\n",
    "    # Optionally pull latest changes\n",
    "    !cd {REPO_DIR} && git pull\n",
    "\n",
    "# Set data path to the cloned repo\n",
    "DATA_DIR = f'./{REPO_DIR}/Fluor-RLAT/data'\n",
    "print(f\"ðŸ“ Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594d8c8",
   "metadata": {},
   "source": [
    "## 4. Verify GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU details\n",
    "!nvidia-smi\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"\\nðŸ–¥ï¸ Using device: {device}\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"   Memory: {props.total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"   Compute capability: {props.major}.{props.minor}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU detected! Training will be slow.\")\n",
    "    print(\"   Go to Runtime â†’ Change runtime type â†’ GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9310c65",
   "metadata": {},
   "source": [
    "## 5. Configure Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c232f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure CUDA memory management to prevent OOM errors\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    # Enable TF32 for faster training on Ampere GPUs (A100)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "print(\"âœ… Environment configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d14da8",
   "metadata": {},
   "source": [
    "## 6. Load and Verify Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54013c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data files are present\n",
    "DATA_DIR = './data'\n",
    "\n",
    "required_base = ['train', 'valid']\n",
    "targets = ['abs', 'em', 'plqy', 'k']\n",
    "file_types = ['', '_smiles', '_sol']\n",
    "\n",
    "print(\"Checking data files...\")\n",
    "missing = []\n",
    "found = []\n",
    "\n",
    "for base in required_base:\n",
    "    for target in targets:\n",
    "        for ftype in file_types:\n",
    "            filename = f'{base}{ftype}_{target}.csv'\n",
    "            path = os.path.join(DATA_DIR, filename)\n",
    "            if os.path.exists(path):\n",
    "                size = os.path.getsize(path) / 1024 / 1024\n",
    "                found.append((filename, size))\n",
    "            else:\n",
    "                missing.append(filename)\n",
    "\n",
    "print(f\"\\nâœ… Found {len(found)} files:\")\n",
    "for fname, size in found[:6]:\n",
    "    print(f\"   {fname} ({size:.1f} MB)\")\n",
    "if len(found) > 6:\n",
    "    print(f\"   ... and {len(found) - 6} more\")\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\nâŒ Missing {len(missing)} files:\")\n",
    "    for fname in missing[:5]:\n",
    "        print(f\"   {fname}\")\n",
    "    print(\"\\nâš ï¸ Please upload data before training!\")\n",
    "else:\n",
    "    print(\"\\nâœ… All required files present!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f8864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample counts\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Dataset sizes:\")\n",
    "for target in ['abs', 'em', 'plqy', 'k']:\n",
    "    train_path = os.path.join(DATA_DIR, f'train_{target}.csv')\n",
    "    valid_path = os.path.join(DATA_DIR, f'valid_{target}.csv')\n",
    "    \n",
    "    if os.path.exists(train_path) and os.path.exists(valid_path):\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        valid_df = pd.read_csv(valid_path)\n",
    "        print(f\"  {target.upper()}: {len(train_df):,} train / {len(valid_df):,} valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde5973",
   "metadata": {},
   "source": [
    "## 7. Initialize Model Architecture\n",
    "\n",
    "Define the complete model architecture including:\n",
    "- AttentiveFP Graph Neural Network\n",
    "- Fingerprint CNN with attention (for abs/em)\n",
    "- Simple FC network (for plqy/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import copy\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import dgl\n",
    "from dgllife.model.gnn import AttentiveFPGNN\n",
    "from dgllife.model.readout import AttentiveFPReadout\n",
    "from dgllife.utils import (\n",
    "    smiles_to_bigraph,\n",
    "    AttentiveFPAtomFeaturizer,\n",
    "    AttentiveFPBondFeaturizer,\n",
    ")\n",
    "\n",
    "print(\"âœ… All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Configuration\n",
    "# ============================================================================\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "GRAPH_FEAT_SIZE = 256\n",
    "\n",
    "# Model configurations per target (from pretrained model analysis)\n",
    "MODEL_CONFIGS = {\n",
    "    'abs': {\n",
    "        'num_layers': 2,\n",
    "        'num_timesteps': 2,\n",
    "        'dropout': 0.3,\n",
    "        'alpha': 0.1,  # LDS alpha\n",
    "        'model_type': 'attention_cnn',\n",
    "    },\n",
    "    'em': {\n",
    "        'num_layers': 2,\n",
    "        'num_timesteps': 1,\n",
    "        'dropout': 0.3,\n",
    "        'alpha': 0.0,\n",
    "        'model_type': 'attention_cnn',\n",
    "    },\n",
    "    'plqy': {\n",
    "        'num_layers': 2,\n",
    "        'num_timesteps': 3,\n",
    "        'dropout': 0.4,\n",
    "        'alpha': 0.2,\n",
    "        'model_type': 'simple_fc',\n",
    "    },\n",
    "    'k': {\n",
    "        'num_layers': 3,\n",
    "        'num_timesteps': 1,\n",
    "        'dropout': 0.3,\n",
    "        'alpha': 0.6,\n",
    "        'model_type': 'simple_fc',\n",
    "    },\n",
    "}\n",
    "\n",
    "# Featurizers for molecular graphs\n",
    "ATOM_FEATURIZER = AttentiveFPAtomFeaturizer(atom_data_field='hv')\n",
    "BOND_FEATURIZER = AttentiveFPBondFeaturizer(bond_data_field='he')\n",
    "\n",
    "print(\"âœ… Configuration loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Model Architecture Classes\n",
    "# ============================================================================\n",
    "\n",
    "class FingerprintAttentionCNN(nn.Module):\n",
    "    \"\"\"CNN with attention for fingerprint processing (used by abs/em models).\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=256, output_dim=512, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.fc_in = nn.Linear(input_dim, hidden_dim)\n",
    "        self.conv1 = nn.Conv1d(1, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv_attn = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=1)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        attn_map = self.conv_attn(x)\n",
    "        attn_weights = torch.softmax(attn_map, dim=-1)\n",
    "        x = x * attn_weights\n",
    "        x = x.mean(dim=-1)\n",
    "        x = self.fc_out(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GraphFingerprintsModelAttentionCNN(nn.Module):\n",
    "    \"\"\"Model for abs/em: AttentiveFP GNN + Attention CNN for fingerprints.\"\"\"\n",
    "    \n",
    "    def __init__(self, node_feat_size, edge_feat_size, solvent_dim, smiles_extra_dim,\n",
    "                 graph_feat_size=256, num_layers=2, num_timesteps=2, n_tasks=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gnn = AttentiveFPGNN(\n",
    "            node_feat_size=node_feat_size,\n",
    "            edge_feat_size=edge_feat_size,\n",
    "            num_layers=num_layers,\n",
    "            graph_feat_size=graph_feat_size,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.readout = AttentiveFPReadout(\n",
    "            feat_size=graph_feat_size,\n",
    "            num_timesteps=num_timesteps,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.solvent_extractor = nn.Sequential(\n",
    "            nn.Linear(solvent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.fp_extractor = FingerprintAttentionCNN(\n",
    "            input_dim=smiles_extra_dim,\n",
    "            hidden_dim=256,\n",
    "            output_dim=512,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, n_tasks)\n",
    "        )\n",
    "        \n",
    "    def forward(self, graph, node_feats, edge_feats, fingerprints):\n",
    "        solvent_feat = fingerprints[:, :2048]\n",
    "        smiles_extra_feat = fingerprints[:, 2048:]\n",
    "        \n",
    "        node_out = self.gnn(graph, node_feats, edge_feats)\n",
    "        graph_out = self.readout(graph, node_out, False)\n",
    "        solvent_out = self.solvent_extractor(solvent_feat)\n",
    "        smiles_extra_out = self.fp_extractor(smiles_extra_feat)\n",
    "        \n",
    "        combined = torch.cat([graph_out, solvent_out, smiles_extra_out], dim=1)\n",
    "        return self.predict(combined)\n",
    "\n",
    "\n",
    "class GraphFingerprintsModelSimpleFC(nn.Module):\n",
    "    \"\"\"Model for plqy/k: AttentiveFP GNN + Simple FC for fingerprints.\"\"\"\n",
    "    \n",
    "    def __init__(self, node_feat_size, edge_feat_size, fp_size,\n",
    "                 graph_feat_size=256, num_layers=2, num_timesteps=2, n_tasks=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gnn = AttentiveFPGNN(\n",
    "            node_feat_size=node_feat_size,\n",
    "            edge_feat_size=edge_feat_size,\n",
    "            num_layers=num_layers,\n",
    "            graph_feat_size=graph_feat_size,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.readout = AttentiveFPReadout(\n",
    "            feat_size=graph_feat_size,\n",
    "            num_timesteps=num_timesteps,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.fp_fc = nn.Sequential(\n",
    "            nn.Linear(fp_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, n_tasks)\n",
    "        )\n",
    "        \n",
    "    def forward(self, graph, node_feats, edge_feats, fingerprints):\n",
    "        node_out = self.gnn(graph, node_feats, edge_feats)\n",
    "        graph_out = self.readout(graph, node_out, False)\n",
    "        fp_out = self.fp_fc(fingerprints)\n",
    "        combined = torch.cat([graph_out, fp_out], dim=1)\n",
    "        return self.predict(combined)\n",
    "\n",
    "\n",
    "print(\"âœ… Model classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178cee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Dataset and Data Loading\n",
    "# ============================================================================\n",
    "\n",
    "class MolecularDataset(Dataset):\n",
    "    \"\"\"Dataset for molecular property prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, graphs, fingerprints, labels, masks=None, weights=None):\n",
    "        self.graphs = graphs\n",
    "        self.fingerprints = fingerprints\n",
    "        self.labels = labels\n",
    "        self.masks = masks\n",
    "        self.weights = weights\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.graphs[idx],\n",
    "            self.fingerprints[idx],\n",
    "            self.labels[idx],\n",
    "            self.masks[idx] if self.masks is not None else 1.0,\n",
    "            self.weights[idx] if self.weights is not None else 1.0\n",
    "        )\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for batching molecular graphs.\"\"\"\n",
    "    graphs, fps, labels, masks, weights = zip(*batch)\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    fps = torch.stack(fps)\n",
    "    labels = torch.stack(labels)\n",
    "    masks = torch.tensor(masks, dtype=torch.float32) if masks[0] is not None else None\n",
    "    weights = torch.tensor(weights, dtype=torch.float32) if weights[0] is not None else None\n",
    "    return batched_graph, fps, labels, masks, weights\n",
    "\n",
    "\n",
    "def compute_lds_weights(labels, alpha=0.5, kernel_size=5):\n",
    "    \"\"\"Compute Label Distribution Smoothing weights.\"\"\"\n",
    "    if alpha == 0:\n",
    "        return np.ones(len(labels))\n",
    "    \n",
    "    n_bins = 100\n",
    "    label_min, label_max = labels.min(), labels.max()\n",
    "    bins = np.linspace(label_min, label_max, n_bins + 1)\n",
    "    bin_indices = np.digitize(labels, bins) - 1\n",
    "    bin_indices = np.clip(bin_indices, 0, n_bins - 1)\n",
    "    \n",
    "    bin_counts = np.bincount(bin_indices, minlength=n_bins).astype(float)\n",
    "    kernel = np.ones(kernel_size) / kernel_size\n",
    "    smoothed_counts = np.convolve(bin_counts, kernel, mode='same')\n",
    "    smoothed_counts = np.maximum(smoothed_counts, 1)\n",
    "    \n",
    "    effective_counts = bin_counts ** alpha * smoothed_counts ** (1 - alpha)\n",
    "    effective_counts = np.maximum(effective_counts, 1)\n",
    "    \n",
    "    weights = 1.0 / effective_counts[bin_indices]\n",
    "    weights = weights / weights.mean()\n",
    "    \n",
    "    return weights.astype(np.float32)\n",
    "\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"Convert SMILES to DGL graph with AttentiveFP featurization.\"\"\"\n",
    "    try:\n",
    "        graph = smiles_to_bigraph(\n",
    "            smiles,\n",
    "            node_featurizer=ATOM_FEATURIZER,\n",
    "            edge_featurizer=BOND_FEATURIZER,\n",
    "            add_self_loop=False\n",
    "        )\n",
    "        return graph\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\"âœ… Dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Data Loading Functions\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_process_data(target, data_dir, config):\n",
    "    \"\"\"Load and process training/validation data for a target property.\"\"\"\n",
    "    \n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # Load main data files\n",
    "    train_df = pd.read_csv(data_dir / f'train_{target}.csv')\n",
    "    valid_df = pd.read_csv(data_dir / f'valid_{target}.csv')\n",
    "    \n",
    "    # Load fingerprint files\n",
    "    train_smiles_fp = pd.read_csv(data_dir / f'train_smiles_{target}.csv')\n",
    "    train_sol_fp = pd.read_csv(data_dir / f'train_sol_{target}.csv')\n",
    "    valid_smiles_fp = pd.read_csv(data_dir / f'valid_smiles_{target}.csv')\n",
    "    valid_sol_fp = pd.read_csv(data_dir / f'valid_sol_{target}.csv')\n",
    "    \n",
    "    print(f\"   Train samples: {len(train_df)}\")\n",
    "    print(f\"   Valid samples: {len(valid_df)}\")\n",
    "    \n",
    "    # Extract labels\n",
    "    train_labels = train_df[target].values.reshape(-1, 1).astype(np.float32)\n",
    "    valid_labels = valid_df[target].values.reshape(-1, 1).astype(np.float32)\n",
    "    \n",
    "    # Normalize labels\n",
    "    scaler = StandardScaler()\n",
    "    train_labels_scaled = scaler.fit_transform(train_labels)\n",
    "    valid_labels_scaled = scaler.transform(valid_labels)\n",
    "    \n",
    "    # Extract and normalize numeric features\n",
    "    numeric_cols = train_df.columns[8:16].tolist() if len(train_df.columns) > 16 else []\n",
    "    \n",
    "    scaler_num = MinMaxScaler()\n",
    "    if numeric_cols:\n",
    "        train_numeric = scaler_num.fit_transform(train_df[numeric_cols].values)\n",
    "        valid_numeric = scaler_num.transform(valid_df[numeric_cols].values)\n",
    "    else:\n",
    "        train_numeric = np.zeros((len(train_df), 0))\n",
    "        valid_numeric = np.zeros((len(valid_df), 0))\n",
    "    \n",
    "    # Combine fingerprints\n",
    "    train_sol = train_sol_fp.values.astype(np.float32)\n",
    "    train_smiles = train_smiles_fp.values.astype(np.float32)\n",
    "    valid_sol = valid_sol_fp.values.astype(np.float32)\n",
    "    valid_smiles = valid_smiles_fp.values.astype(np.float32)\n",
    "    \n",
    "    # Get scaffold flags if present\n",
    "    scaffold_cols = [c for c in train_df.columns if c.startswith('fragment_')]\n",
    "    if scaffold_cols:\n",
    "        train_scaffold = train_df[scaffold_cols].values.astype(np.float32)\n",
    "        valid_scaffold = valid_df[scaffold_cols].values.astype(np.float32)\n",
    "    else:\n",
    "        train_scaffold = np.zeros((len(train_df), 0), dtype=np.float32)\n",
    "        valid_scaffold = np.zeros((len(valid_df), 0), dtype=np.float32)\n",
    "    \n",
    "    # Combine all features\n",
    "    train_fp = np.hstack([train_sol, train_smiles, train_numeric, train_scaffold])\n",
    "    valid_fp = np.hstack([valid_sol, valid_smiles, valid_numeric, valid_scaffold])\n",
    "    \n",
    "    solvent_dim = train_sol.shape[1]\n",
    "    smiles_extra_dim = train_fp.shape[1] - solvent_dim\n",
    "    fp_size = train_fp.shape[1]\n",
    "    \n",
    "    print(f\"   Total fingerprint dimensions: {fp_size}\")\n",
    "    \n",
    "    # Compute LDS weights\n",
    "    alpha = config['alpha']\n",
    "    train_weights = compute_lds_weights(train_labels.flatten(), alpha=alpha)\n",
    "    print(f\"   LDS alpha: {alpha}, weight range: [{train_weights.min():.2f}, {train_weights.max():.2f}]\")\n",
    "    \n",
    "    # Convert SMILES to graphs\n",
    "    print(\"   Converting SMILES to graphs...\")\n",
    "    \n",
    "    train_smiles_list = train_df['smiles'].tolist()\n",
    "    valid_smiles_list = valid_df['smiles'].tolist()\n",
    "    \n",
    "    train_graphs = []\n",
    "    for smi in tqdm(train_smiles_list, desc=\"   Train graphs\", leave=False):\n",
    "        g = smiles_to_graph(smi)\n",
    "        if g is None:\n",
    "            g = dgl.graph(([0], [0]))\n",
    "            g.ndata['hv'] = torch.zeros(1, 39)\n",
    "            g.edata['he'] = torch.zeros(1, 10)\n",
    "        train_graphs.append(g)\n",
    "    \n",
    "    valid_graphs = []\n",
    "    for smi in tqdm(valid_smiles_list, desc=\"   Valid graphs\", leave=False):\n",
    "        g = smiles_to_graph(smi)\n",
    "        if g is None:\n",
    "            g = dgl.graph(([0], [0]))\n",
    "            g.ndata['hv'] = torch.zeros(1, 39)\n",
    "            g.edata['he'] = torch.zeros(1, 10)\n",
    "        valid_graphs.append(g)\n",
    "    \n",
    "    print(f\"   âœ… Converted {len(train_graphs)} train + {len(valid_graphs)} valid graphs\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_data = MolecularDataset(\n",
    "        graphs=train_graphs,\n",
    "        fingerprints=torch.tensor(train_fp, dtype=torch.float32),\n",
    "        labels=torch.tensor(train_labels_scaled, dtype=torch.float32),\n",
    "        masks=None,\n",
    "        weights=train_weights\n",
    "    )\n",
    "    \n",
    "    valid_data = MolecularDataset(\n",
    "        graphs=valid_graphs,\n",
    "        fingerprints=torch.tensor(valid_fp, dtype=torch.float32),\n",
    "        labels=torch.tensor(valid_labels_scaled, dtype=torch.float32),\n",
    "        masks=None,\n",
    "        weights=None\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'train_data': train_data,\n",
    "        'valid_data': valid_data,\n",
    "        'scaler': scaler,\n",
    "        'scaler_num': scaler_num,\n",
    "        'config': config,\n",
    "        'solvent_dim': solvent_dim,\n",
    "        'smiles_extra_dim': smiles_extra_dim,\n",
    "        'fp_size': fp_size,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ… Data loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Training Functions\n",
    "# ============================================================================\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device, use_lds=True):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        graphs, fps, labels, masks, weights = batch\n",
    "        \n",
    "        graphs = graphs.to(device)\n",
    "        fps = fps.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        node_feats = graphs.ndata['hv']\n",
    "        edge_feats = graphs.edata.get('he', None)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(graphs, node_feats, edge_feats, fps)\n",
    "        \n",
    "        if use_lds and weights is not None:\n",
    "            weights = weights.to(device)\n",
    "            loss = (criterion(predictions, labels) * weights.unsqueeze(1)).mean()\n",
    "        else:\n",
    "            loss = criterion(predictions, labels).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate model on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            graphs, fps, labels, masks, _ = batch\n",
    "            \n",
    "            graphs = graphs.to(device)\n",
    "            fps = fps.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            node_feats = graphs.ndata['hv']\n",
    "            edge_feats = graphs.edata.get('he', None)\n",
    "            \n",
    "            predictions = model(graphs, node_feats, edge_feats, fps)\n",
    "            loss = criterion(predictions, labels).mean()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            all_preds.append(predictions.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    return total_loss / num_batches, all_preds, all_labels\n",
    "\n",
    "\n",
    "print(\"âœ… Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efa11c",
   "metadata": {},
   "source": [
    "## 8. Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Main Training Function\n",
    "# ============================================================================\n",
    "\n",
    "def train_model(target, data_dir='./data', output_dir='./models', \n",
    "                checkpoint_dir='./checkpoints', epochs=200, patience=20, device='cuda'):\n",
    "    \"\"\"Train a single property prediction model with checkpoint saving.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸš€ Training model for: {target.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get model config\n",
    "    config = MODEL_CONFIGS[target]\n",
    "    print(f\"   Config: {config}\")\n",
    "    \n",
    "    # Get feature dimensions\n",
    "    sample_graph = smiles_to_graph('CCO')\n",
    "    n_feats = sample_graph.ndata['hv'].shape[1]\n",
    "    e_feats = sample_graph.edata['he'].shape[1]\n",
    "    print(f\"   Node features: {n_feats}, Edge features: {e_feats}\")\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"\\nðŸ“‚ Loading data for {target}...\")\n",
    "    data = load_and_process_data(target, data_dir, config)\n",
    "    \n",
    "    # Create data loaders with GPU optimization\n",
    "    train_loader = DataLoader(\n",
    "        data['train_data'],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        data['valid_data'],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    if config['model_type'] == 'attention_cnn':\n",
    "        model = GraphFingerprintsModelAttentionCNN(\n",
    "            node_feat_size=n_feats,\n",
    "            edge_feat_size=e_feats,\n",
    "            solvent_dim=data['solvent_dim'],\n",
    "            smiles_extra_dim=data['smiles_extra_dim'],\n",
    "            graph_feat_size=GRAPH_FEAT_SIZE,\n",
    "            num_layers=config['num_layers'],\n",
    "            num_timesteps=config['num_timesteps'],\n",
    "            n_tasks=1,\n",
    "            dropout=config['dropout']\n",
    "        ).to(device)\n",
    "    else:\n",
    "        model = GraphFingerprintsModelSimpleFC(\n",
    "            node_feat_size=n_feats,\n",
    "            edge_feat_size=e_feats,\n",
    "            fp_size=data['fp_size'],\n",
    "            graph_feat_size=GRAPH_FEAT_SIZE,\n",
    "            num_layers=config['num_layers'],\n",
    "            num_timesteps=config['num_timesteps'],\n",
    "            n_tasks=1,\n",
    "            dropout=config['dropout']\n",
    "        ).to(device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"   Model parameters: {total_params:,}\")\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_without_improvement = 0\n",
    "    use_lds = config['alpha'] > 0\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Starting training (max {epochs} epochs, patience {patience})...\")\n",
    "    print(f\"   Using LDS: {use_lds}\")\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    # Monitor GPU memory\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    pbar = tqdm(range(1, epochs + 1), desc=\"Training\", unit=\"epoch\")\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device, use_lds)\n",
    "        val_loss, val_preds, val_labels = validate(model, valid_loader, criterion, device)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            epochs_without_improvement = 0\n",
    "            status = \"âœ“ best\"\n",
    "            \n",
    "            # Save checkpoint to Google Drive\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{target}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': best_model_state,\n",
    "                'val_loss': best_val_loss,\n",
    "            }, checkpoint_path)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            status = \"\"\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'train': f'{train_loss:.4f}',\n",
    "            'val': f'{val_loss:.4f}',\n",
    "            'best': f'{best_val_loss:.4f}',\n",
    "            'status': status\n",
    "        })\n",
    "        \n",
    "        # Early stopping\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"\\nâ¹ï¸ Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    _, val_preds, val_labels = validate(model, valid_loader, criterion, device)\n",
    "    \n",
    "    # Inverse transform predictions\n",
    "    val_preds_orig = data['scaler'].inverse_transform(val_preds)\n",
    "    val_labels_orig = data['scaler'].inverse_transform(val_labels)\n",
    "    \n",
    "    mae = mean_absolute_error(val_labels_orig, val_preds_orig)\n",
    "    rmse = np.sqrt(mean_squared_error(val_labels_orig, val_preds_orig))\n",
    "    r2 = r2_score(val_labels_orig, val_preds_orig)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Final Metrics (original scale):\")\n",
    "    print(f\"   MAE:  {mae:.4f}\")\n",
    "    print(f\"   RMSE: {rmse:.4f}\")\n",
    "    print(f\"   RÂ²:   {r2:.4f}\")\n",
    "    \n",
    "    # Report GPU memory usage\n",
    "    if device == 'cuda':\n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1e9\n",
    "        print(f\"   Peak GPU memory: {peak_memory:.2f} GB\")\n",
    "    \n",
    "    # Save final model\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model_path = os.path.join(output_dir, f'Model_{target}.pth')\n",
    "    torch.save(best_model_state, model_path)\n",
    "    print(f\"\\nðŸ’¾ Model saved to: {model_path}\")\n",
    "    \n",
    "    # Calculate training time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, remainder = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    time_str = f\"{int(hours)}h {int(minutes)}m {int(seconds)}s\"\n",
    "    print(f\"â±ï¸ Training time: {time_str}\")\n",
    "    \n",
    "    return {\n",
    "        'target': target,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'epochs_trained': epoch,\n",
    "        'training_time': elapsed_time,\n",
    "        'history': history,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ… Main training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1bd423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Training Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# Paths - using cloned repository data\n",
    "DATA_DIR = './fluor_tools/Fluor-RLAT/data'\n",
    "OUTPUT_DIR = './models'\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/fluor_checkpoints'  # Save checkpoints to Drive\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 200\n",
    "PATIENCE = 20\n",
    "\n",
    "# Select which models to train\n",
    "# Options: 'abs', 'em', 'plqy', 'k'\n",
    "TARGETS = ['abs', 'em', 'plqy', 'k']  # Train all models\n",
    "# TARGETS = ['abs']  # Train only absorption model\n",
    "\n",
    "print(f\"ðŸŽ¯ Models to train: {TARGETS}\")\n",
    "print(f\"ðŸ“ Data directory: {DATA_DIR}\")\n",
    "print(f\"ðŸ“ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"ðŸ’¾ Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"âš™ï¸  Epochs: {EPOCHS}, Patience: {PATIENCE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff5487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ðŸš€ START TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "total_start = time.time()\n",
    "results = []\n",
    "\n",
    "for target in TARGETS:\n",
    "    result = train_model(\n",
    "        target=target,\n",
    "        data_dir=DATA_DIR,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        checkpoint_dir=CHECKPOINT_DIR,\n",
    "        epochs=EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        device=device\n",
    "    )\n",
    "    results.append(result)\n",
    "    \n",
    "    # Clear GPU cache between models\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "total_elapsed = time.time() - total_start\n",
    "\n",
    "# ============================================================================\n",
    "# Summary\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ðŸ“‹ TRAINING SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for r in results:\n",
    "    t = r['training_time']\n",
    "    h, rem = divmod(t, 3600)\n",
    "    m, s = divmod(rem, 60)\n",
    "    time_str = f\"{int(h)}h {int(m)}m {int(s)}s\"\n",
    "    \n",
    "    print(f\"\\n{r['target'].upper()}:\")\n",
    "    print(f\"   Epochs: {r['epochs_trained']}, Time: {time_str}\")\n",
    "    print(f\"   MAE: {r['mae']:.4f}, RMSE: {r['rmse']:.4f}, RÂ²: {r['r2']:.4f}\")\n",
    "\n",
    "total_h, total_rem = divmod(total_elapsed, 3600)\n",
    "total_m, total_s = divmod(total_rem, 60)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"â±ï¸ Total training time: {int(total_h)}h {int(total_m)}m {int(total_s)}s\")\n",
    "print(f\"âœ… Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b09a1",
   "metadata": {},
   "source": [
    "## 9. Download Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b84758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List trained models\n",
    "print(\"Trained models:\")\n",
    "for f in os.listdir(OUTPUT_DIR):\n",
    "    if f.endswith('.pth'):\n",
    "        size = os.path.getsize(os.path.join(OUTPUT_DIR, f)) / 1e6\n",
    "        print(f\"  ðŸ“¦ {f} ({size:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Download directly to your computer\n",
    "from google.colab import files\n",
    "\n",
    "for f in os.listdir(OUTPUT_DIR):\n",
    "    if f.endswith('.pth'):\n",
    "        files.download(os.path.join(OUTPUT_DIR, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Copy to Google Drive\n",
    "DRIVE_OUTPUT = \"/content/drive/MyDrive/fluor_models\"\n",
    "os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n",
    "\n",
    "for f in os.listdir(OUTPUT_DIR):\n",
    "    if f.endswith('.pth'):\n",
    "        src = os.path.join(OUTPUT_DIR, f)\n",
    "        dst = os.path.join(DRIVE_OUTPUT, f)\n",
    "        !cp \"{src}\" \"{dst}\"\n",
    "\n",
    "print(f\"âœ… Models copied to: {DRIVE_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb540a",
   "metadata": {},
   "source": [
    "## 10. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8702ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, r in enumerate(results):\n",
    "    if idx >= 4:\n",
    "        break\n",
    "    ax = axes[idx]\n",
    "    ax.plot(r['history']['train_loss'], label='Train Loss', alpha=0.8)\n",
    "    ax.plot(r['history']['val_loss'], label='Val Loss', alpha=0.8)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title(f\"{r['target'].upper()} - MAE: {r['mae']:.2f}, RÂ²: {r['r2']:.3f}\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(len(results), 4):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to Google Drive\n",
    "plot_path = os.path.join(DRIVE_OUTPUT, 'training_history.png')\n",
    "plt.savefig(plot_path, dpi=150)\n",
    "plt.show()\n",
    "print(f\"ðŸ“Š Plot saved to: {plot_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
